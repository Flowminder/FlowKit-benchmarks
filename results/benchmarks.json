{
    "benchmarks.AggregateDailyLocation.time_aggregate_daily_location": {
        "code": "class AggregateDailyLocation:\n    def time_aggregate_daily_location(self, *args):\n    \n        _ = self.dl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.dl = dl.aggregate()\n        self.dl.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.AggregateDailyLocation.time_aggregate_daily_location",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "2b5a292afc5db7a8707dcce8c29f1107aec1901d4cc92e4dac82f089db4cfd69",
        "warmup_time": -1
    },
    "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost": {
        "code": "class AggregateDailyLocation:\n    def track_aggregate_daily_location_cost(self, *args):\n        return self.dl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.dl = dl.aggregate()\n        self.dl.turn_off_caching()",
        "name": "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "bde1065ea280e8397b25cbb92d172580bc35e02afaa92451459414cc7ca68e3f"
    },
    "benchmarks.AggregateModalLocation.time_aggregate_modal_location": {
        "code": "class AggregateModalLocation:\n    def time_aggregate_modal_location(self, *args):\n        _ = self.ml.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.ml = ml.aggregate()\n        self.ml.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.AggregateModalLocation.time_aggregate_modal_location",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "91702f6f9feee787e59bea38e7c6db1214b1b9ed48062c08ce05d02f309f61be",
        "warmup_time": -1
    },
    "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost": {
        "code": "class AggregateModalLocation:\n    def track_aggregate_modal_location_cost(self, *args):\n        return self.ml.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.ml = ml.aggregate()\n        self.ml.turn_off_caching()",
        "name": "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "8552ae0b97b70fe5e5b73091119563c77561a81d32bb55ce96aacf388fb97671"
    },
    "benchmarks.DailyLocation.time_daily_location": {
        "code": "class DailyLocation:\n    def time_daily_location(self, *args):\n    \n        _ = self.dl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.dl.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.DailyLocation.time_daily_location",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "f344a70e9089de3e7d94dd36a777132803a7aee682b002ae14605f0375c7dad1",
        "warmup_time": -1
    },
    "benchmarks.DailyLocation.track_daily_location_cost": {
        "code": "class DailyLocation:\n    def track_daily_location_cost(self, *args):\n        return self.dl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.dl.turn_off_caching()",
        "name": "benchmarks.DailyLocation.track_daily_location_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "1807c2e59a83bc612ca5c75db5036cb51417bff32882f36b30cff37b3af722ea"
    },
    "benchmarks.FlowSuite.time_flow": {
        "code": "class FlowSuite:\n    def time_flow(self, *args):\n        _ = self.fl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.fl = Flows(*mls)\n        self.fl.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.FlowSuite.time_flow",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "1",
                "2"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "b9cd4d8dbff08109271998cabe7a7470758112e8f9f912efc94f06e00112ada7",
        "warmup_time": -1
    },
    "benchmarks.FlowSuite.track_flow_cost": {
        "code": "class FlowSuite:\n    def track_flow_cost(self, *args):\n        return self.fl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.fl = Flows(*mls)\n        self.fl.turn_off_caching()",
        "name": "benchmarks.FlowSuite.track_flow_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "1",
                "2"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0f8aaf415e19b6a68444ce7a0066725d61fe4fce9c3ef140100dc61eceba8421"
    },
    "benchmarks.ModalLocationWithCaching.time_modal_location": {
        "code": "class ModalLocationWithCaching:\n    def time_modal_location(self, *args):\n        _ = self.ml.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.ml = ModalLocation(*daily_locs)\n        self.ml.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.ModalLocationWithCaching.time_modal_location",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "3",
                "7"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "567c00654fab574eaf7ae4c9b6bc3e6e11f60cb9ffb6e5144eebf09b2c650a35",
        "warmup_time": -1
    },
    "benchmarks.ModalLocationWithCaching.track_modal_location_cost": {
        "code": "class ModalLocationWithCaching:\n    def track_modal_location_cost(self, *args):\n        return self.ml.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.ml = ModalLocation(*daily_locs)\n        self.ml.turn_off_caching()",
        "name": "benchmarks.ModalLocationWithCaching.track_modal_location_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "3",
                "7"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "ffdd02ede688977fad2c1ac935a3a459b1ec767b2fd845b3b12add9b4d948f7a"
    },
    "benchmarks.TotalLocationEventsSuite.time_total_location_events": {
        "code": "class TotalLocationEventsSuite:\n    def time_total_location_events(self, *args):\n        _ = self.tle.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.tle = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.tle.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.TotalLocationEventsSuite.time_total_location_events",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "interval",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'admin3'"
            ],
            [
                "'day'",
                "'min'"
            ],
            [
                "'out'",
                "'both'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "c8c82ae515935064c23d58c8d65ecd86af326292491da85307e99fe282d0ef6b",
        "warmup_time": -1
    },
    "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost": {
        "code": "class TotalLocationEventsSuite:\n    def track_total_location_events_cost(self, *args):\n        return self.tle.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.tle = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.tle.turn_off_caching()",
        "name": "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "interval",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'admin3'"
            ],
            [
                "'day'",
                "'min'"
            ],
            [
                "'out'",
                "'both'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "47813d71b2590d9dd53ba7111486f1e6d9b883cd9c6137940a81ed2eaef89b58"
    },
    "version": 2
}