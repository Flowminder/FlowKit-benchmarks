{
    "benchmarks.AggregateDailyLocation.time_query": {
        "code": "class AggregateDailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.AggregateDailyLocation.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.AggregateDailyLocation.track_cost": {
        "code": "class AggregateDailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()",
        "name": "benchmarks.AggregateDailyLocation.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.AggregateModalLocation.time_query": {
        "code": "class AggregateModalLocation:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.AggregateModalLocation.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.AggregateModalLocation.track_cost": {
        "code": "class AggregateModalLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()",
        "name": "benchmarks.AggregateModalLocation.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "is_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.AggregateNetworkObjectsSuite.time_query": {
        "code": "class AggregateNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\", \"2016-01-07\", total_by=\"minute\", level=\"admin3\"\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.AggregateNetworkObjectsSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "statistic",
            "aggregate_by",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'avg'",
                "'max'",
                "'min'",
                "'median'",
                "'mode'",
                "'stddev'",
                "'variance'"
            ],
            [
                "'hour'",
                "'month'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.AggregateNetworkObjectsSuite.track_cost": {
        "code": "class AggregateNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\", \"2016-01-07\", total_by=\"minute\", level=\"admin3\"\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.AggregateNetworkObjectsSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "statistic",
            "aggregate_by",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'avg'",
                "'max'",
                "'min'",
                "'median'",
                "'mode'",
                "'stddev'",
                "'variance'"
            ],
            [
                "'hour'",
                "'month'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.DFSTotalMetricAmountSuite.time_query": {
        "code": "class DFSTotalMetricAmountSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.DFSTotalMetricAmountSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "metric",
            "aggregation_unit"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'amount'",
                "'discount'",
                "'fee'",
                "'commission'"
            ],
            [
                "'admin0'",
                "'admin3'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.DFSTotalMetricAmountSuite.track_cost": {
        "code": "class DFSTotalMetricAmountSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.DFSTotalMetricAmountSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "metric",
            "aggregation_unit"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'amount'",
                "'discount'",
                "'fee'",
                "'commission'"
            ],
            [
                "'admin0'",
                "'admin3'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.DailyLocation.time_query": {
        "code": "class DailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.DailyLocation.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.DailyLocation.track_cost": {
        "code": "class DailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()",
        "name": "benchmarks.DailyLocation.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.EventScoreSuite.time_query": {
        "code": "class EventScoreSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.EventScoreSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "hours"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'versioned-cell'",
                "'admin3'"
            ],
            [
                "(4, 17)",
                "'all'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.EventScoreSuite.track_cost": {
        "code": "class EventScoreSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.EventScoreSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "hours"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'versioned-cell'",
                "'admin3'"
            ],
            [
                "(4, 17)",
                "'all'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.FlowSuite.time_query": {
        "code": "class FlowSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.FlowSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "1",
                "2"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.FlowSuite.track_cost": {
        "code": "class FlowSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()",
        "name": "benchmarks.FlowSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "1",
                "2"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.HartiganClusterSuite.time_query": {
        "code": "class HartiganClusterSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.HartiganClusterSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "hours",
            "radius"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "(4, 17)",
                "'all'"
            ],
            [
                "0.1",
                "10.0"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.HartiganClusterSuite.track_cost": {
        "code": "class HartiganClusterSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.HartiganClusterSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "hours",
            "radius"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "(4, 17)",
                "'all'"
            ],
            [
                "0.1",
                "10.0"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query": {
        "code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "method",
            "metric_cached",
            "locations_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'avg'",
                "'max'",
                "'min'",
                "'median'",
                "'mode'",
                "'stddev'",
                "'variance'"
            ],
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost": {
        "code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()",
        "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "method",
            "metric_cached",
            "locations_cached"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'avg'",
                "'max'",
                "'min'",
                "'median'",
                "'mode'",
                "'stddev'",
                "'variance'"
            ],
            [
                "True",
                "False"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.LocationIntroversionSuite.time_query": {
        "code": "class LocationIntroversionSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], direction=args[-1]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.LocationIntroversionSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'admin3'",
                "'admin0'"
            ],
            [
                "'in'",
                "'both'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.LocationIntroversionSuite.track_cost": {
        "code": "class LocationIntroversionSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], direction=args[-1]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.LocationIntroversionSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'admin3'",
                "'admin0'"
            ],
            [
                "'in'",
                "'both'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.MeaningfulLocationsAggregateSuite.time_query": {
        "code": "class MeaningfulLocationsAggregateSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.MeaningfulLocationsAggregateSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'admin1'",
                "'admin3'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.MeaningfulLocationsAggregateSuite.track_cost": {
        "code": "class MeaningfulLocationsAggregateSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.MeaningfulLocationsAggregateSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'admin1'",
                "'admin3'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.MeaningfulLocationsODSuite.time_query": {
        "code": "class MeaningfulLocationsODSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.MeaningfulLocationsODSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'admin1'",
                "'admin3'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.MeaningfulLocationsODSuite.track_cost": {
        "code": "class MeaningfulLocationsODSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.MeaningfulLocationsODSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'admin1'",
                "'admin3'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.MeaningfulLocationsSuite.time_query": {
        "code": "class MeaningfulLocationsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.MeaningfulLocationsSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "label",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'day'",
                "'unknown'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.MeaningfulLocationsSuite.track_cost": {
        "code": "class MeaningfulLocationsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.MeaningfulLocationsSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "label",
            "caching"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'day'",
                "'unknown'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.ModalLocationWithCaching.time_query": {
        "code": "class ModalLocationWithCaching:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.ModalLocationWithCaching.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "3",
                "7"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.ModalLocationWithCaching.track_cost": {
        "code": "class ModalLocationWithCaching:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()",
        "name": "benchmarks.ModalLocationWithCaching.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "n_cached",
            "daily_location_method"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "0",
                "3",
                "7"
            ],
            [
                "'last'",
                "'most-common'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.RadiusOfGyrationSuite.time_query": {
        "code": "class RadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.RadiusOfGyrationSuite.time_query",
        "number": 0,
        "param_names": [],
        "params": [],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.RadiusOfGyrationSuite.track_cost": {
        "code": "class RadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()",
        "name": "benchmarks.RadiusOfGyrationSuite.track_cost",
        "param_names": [],
        "params": [],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.TotalLocationEventsSuite.time_query": {
        "code": "class TotalLocationEventsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.TotalLocationEventsSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "interval",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'admin3'"
            ],
            [
                "'day'",
                "'min'"
            ],
            [
                "'out'",
                "'both'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.TotalLocationEventsSuite.track_cost": {
        "code": "class TotalLocationEventsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.TotalLocationEventsSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "interval",
            "direction"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'admin3'"
            ],
            [
                "'day'",
                "'min'"
            ],
            [
                "'out'",
                "'both'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.TotalNetworkObjectsSuite.time_query": {
        "code": "class TotalNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=args[-2],\n            level=args[-1],\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.TotalNetworkObjectsSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "total_by",
            "network_object",
            "level"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'minute'",
                "'day'"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'versioned-site'"
            ],
            [
                "'admin0'",
                "'admin3'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.TotalNetworkObjectsSuite.track_cost": {
        "code": "class TotalNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=args[-2],\n            level=args[-1],\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.TotalNetworkObjectsSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "total_by",
            "network_object",
            "level"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'minute'",
                "'day'"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'versioned-site'"
            ],
            [
                "'admin0'",
                "'admin3'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "benchmarks.UniqueSubscriberCountsSuite.time_query": {
        "code": "class UniqueSubscriberCountsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()",
        "min_run_count": 2,
        "name": "benchmarks.UniqueSubscriberCountsSuite.time_query",
        "number": 0,
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "hours"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'admin3'",
                "'admin0'"
            ],
            [
                "(4, 17)",
                "'all'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 1200,
        "type": "time",
        "unit": "seconds",
        "version": "0",
        "warmup_time": -1
    },
    "benchmarks.UniqueSubscriberCountsSuite.track_cost": {
        "code": "class UniqueSubscriberCountsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        db_pass=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()",
        "name": "benchmarks.UniqueSubscriberCountsSuite.track_cost",
        "param_names": [
            "num_days",
            "num_subscribers",
            "num_cells",
            "num_calls_per_day",
            "analyze",
            "cluster",
            "jit",
            "level",
            "hours"
        ],
        "params": [
            [
                "7"
            ],
            [
                "1000"
            ],
            [
                "400"
            ],
            [
                "10000"
            ],
            [
                "True"
            ],
            [
                "True"
            ],
            [
                "False"
            ],
            [
                "'cell'",
                "'versioned-cell'",
                "'admin3'",
                "'admin0'"
            ],
            [
                "(4, 17)",
                "'all'"
            ]
        ],
        "timeout": 1200,
        "type": "track",
        "unit": "unit",
        "version": "0"
    },
    "version": 2
}