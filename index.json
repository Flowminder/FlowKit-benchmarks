{"project": "FlowKit", "project_url": "https://github.com/Flowminder/FlowKit", "show_commit_url": "https://github.com/Flowminder/FlowKit/commit/", "hash_length": 8, "revision_to_hash": {"4": "a5c731e23308928c75b5267535280aab0c7e4bf7", "16": "2ca58e1d7cdaf14c8f8f2aed545cf961acbde5c0", "260": "bf9d1ae891afe9def7406b6922931a8d16017b56", "463": "251e3977decb56c2e6a78fbee21ac57aed2b31c3", "640": "fa5a5dc823aa4292b6117aee25c7413556d2f55f", "1021": "f51abc5156fcf4815f0ff6d46ac32bf68d535fa9", "1095": "2ece3e59ffcba344f056469ebd51a005f2f95159", "1103": "1249570256e017e91eee51b23d9cdbe516a5c84c", "1159": "48b2df56923ae1cb200a7f5c97dad095c7f57ff6", "1221": "2b3b912095cc44119eb3d8597662737aa827ea9c", "1298": "91d09988496d81968032cda244e0cc1bed24f814", "1367": "d03096a0ca9b89972d02dc2e9e71c3f50963f5bf", "1370": "6776a308c9f575441333a3a2dfafc7a441568893", "1372": "d42159e39d8c9dfefa8d454455bb74c986b929dc", "1403": "7adffdf661980f4783a2ae5b4bdfb21d737cd7dd", "1420": "24f28700b3ae8afdb9c4b5490b41cbfaa337b8f4", "1489": "f5d55d88a2aa2db5539655cac243ec805f5eb446", "1598": "97013831cc176f7e7284c2e413caff901835bee1", "1599": "b73d67a8f5e84662d28a6e382af3038dbf6f0765", "1612": "b01b3d236b075d3ab9a72f925fd7f816d147388b", "2264": "f4dd8af791fab7532bbf41124c95f82d989cfb6c", "2354": "81e54ef05eb0d26fe0dd99ee74273e6722981cb2", "2364": "6d97ee7859d7845de0b8c2ec546af76ef7e53ea1", "2369": "f798f86617bd3680fd187c2fd2acaaa610b99e81", "2373": "4030a7f8fa00c481011d02e2e1ea5b5d95c1c09b", "2434": "73dbf663bab467d16d6ed9d0a2b9086ed9c9d1fc", "2511": "06f10a59680c0ab8eff05aaec916bb539b441f65", "2527": "f3da415dd1e1a184cf38f4e95a80eed75be1a5c6", "2539": "343f829e9f4383c889579ff0418f8418470e6265", "2547": "e18604361454ace228a4656d40bdaa6728fcf86f", "2596": "bc9474bd14e3f590d31e059b823e5794524456d7", "2622": "ca83f279a29adc5faf36f3831a78f6dfa3238042", "2636": "6aea272f8c7faabe89d2ae8c226c9ab1bf61ec30", "2650": "799a950e8324fc857cf0c44959f3cc4a6c964dd5", "2666": "96051c4efc13889a52539f449acfb7508d2cfaa6", "2674": "79a5cf438ce982159ef7a499ce8f55ea4d8faba0", "2689": "f413d1cf5cbc2a716640c0163ffcab9cff37b2eb", "2698": "d2aba155e3ac0a164021742d6607a491e543106d", "2727": "b8eeb053ca37017087d6938e13ac660fc7b22600", "2751": "a7bbfe97fbce28e03d6fbb5faaf6495b050ee27b", "2788": "be1c5ea7325ad4c4d0f5522cc29341c2782b8410", "2812": "626a4bcf4205ef6fdaaa6ac49d6bde7056e02575", "2818": "19919e065249bbc0fb95714824c73513a81b8e35", "2821": "fb1b85a3d1633e637c43907ddf033265733a6f6c", "2829": "49e9fb75dda8cb30a71e39211b84dc3448d2e7f5", "3317": "131c64ece8588da3bec6528405dd057d74aaaf96", "3334": "06c639c8d70b059fc0cb79d664b197868e080387"}, "revision_to_date": {"4": 1541031481000, "16": 1541087949000, "260": 1541703719000, "463": 1543252162000, "640": 1544098755000, "1021": 1547543855000, "1095": 1547646794000, "1103": 1547652761000, "1159": 1547657857000, "1221": 1547724887000, "1298": 1547760280000, "1367": 1548218319000, "1370": 1548220081000, "1372": 1548220851000, "1403": 1548268741000, "1420": 1548339523000, "1489": 1548676131000, "1598": 1548928569000, "1599": 1548929830000, "1612": 1548937596000, "2264": 1551351987000, "2354": 1551736605000, "2364": 1551785643000, "2369": 1551790073000, "2373": 1551790437000, "2434": 1551846540000, "2511": 1551914548000, "2527": 1551960956000, "2539": 1552160824000, "2547": 1552303388000, "2596": 1552325793000, "2622": 1552391768000, "2636": 1552397399000, "2650": 1552413329000, "2666": 1552517051000, "2674": 1552559446000, "2689": 1552667101000, "2698": 1552762910000, "2727": 1552767049000, "2751": 1552909352000, "2788": 1553205140000, "2812": 1553276739000, "2818": 1553511299000, "2821": 1553598533000, "2829": 1553600855000, "3317": 1553814046000, "3334": 1553835135000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz"], "docker": [""], "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": ["", null], "halo": [""], "machine": ["tomte"], "os": ["Linux 3.10.0-693.21.1.el7.x86_64"], "python": ["3.7"], "ram": ["131746656"], "/home/jamesharrison/synthie": ["", null], "branch": ["master"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "/home/jamesharrison/synthie": null}, {"/home/jamesharrison/synthie": "", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": null}], "benchmarks": {"benchmarks.AggregateDailyLocation.time_aggregate_daily_location": {"code": "class AggregateDailyLocation:\n    def time_aggregate_daily_location(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = dl.aggregate()\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateDailyLocation.time_aggregate_daily_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost": {"code": "class AggregateDailyLocation:\n    def track_aggregate_daily_location_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = dl.aggregate()\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateModalLocation.time_aggregate_modal_location": {"code": "class AggregateModalLocation:\n    def time_aggregate_modal_location(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = ml.aggregate()\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateModalLocation.time_aggregate_modal_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost": {"code": "class AggregateModalLocation:\n    def track_aggregate_modal_location_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = ml.aggregate()\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DailyLocation.time_daily_location": {"code": "class DailyLocation:\n    def time_daily_location(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DailyLocation.time_daily_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DailyLocation.track_daily_location_cost": {"code": "class DailyLocation:\n    def track_daily_location_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "name": "benchmarks.DailyLocation.track_daily_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.EventScoreSuite.time_event_score": {"code": "class EventScoreSuite:\n    def time_event_score(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.EventScoreSuite.time_event_score", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'versioned-cell'", "'admin3'"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.EventScoreSuite.track_event_score_cost": {"code": "class EventScoreSuite:\n    def track_event_score_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.EventScoreSuite.track_event_score_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'versioned-cell'", "'admin3'"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.FlowSuite.time_flow": {"code": "class FlowSuite:\n    def time_flow(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.FlowSuite.time_flow", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.FlowSuite.track_flow_cost": {"code": "class FlowSuite:\n    def track_flow_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "name": "benchmarks.FlowSuite.track_flow_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.HartiganClusterSuite.time_hartigan_cluster": {"code": "class HartiganClusterSuite:\n    def time_hartigan_cluster(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.HartiganClusterSuite.time_hartigan_cluster", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.HartiganClusterSuite.track_hartigan_cluster_cost": {"code": "class HartiganClusterSuite:\n    def track_hartigan_cluster_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.HartiganClusterSuite.track_hartigan_cluster_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsAggregateSuite.time_meaningful_locations_aggregate": {"code": "class MeaningfulLocationsAggregateSuite:\n    def time_meaningful_locations_aggregate(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsAggregateSuite.time_meaningful_locations_aggregate", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsAggregateSuite.track_meaningful_locations_aggregate_cost": {"code": "class MeaningfulLocationsAggregateSuite:\n    def track_meaningful_locations_aggregate_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsAggregateSuite.track_meaningful_locations_aggregate_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsODSuite.time_meaningful_locations_aggregate": {"code": "class MeaningfulLocationsODSuite:\n    def time_meaningful_locations_aggregate(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsODSuite.time_meaningful_locations_aggregate", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsODSuite.track_meaningful_locations_aggregate_cost": {"code": "class MeaningfulLocationsODSuite:\n    def track_meaningful_locations_aggregate_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsODSuite.track_meaningful_locations_aggregate_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsSuite.time_meaningful_locations": {"code": "class MeaningfulLocationsSuite:\n    def time_meaningful_locations(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsSuite.time_meaningful_locations", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsSuite.track_meaningful_locations_cost": {"code": "class MeaningfulLocationsSuite:\n    def track_meaningful_locations_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsSuite.track_meaningful_locations_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.ModalLocationWithCaching.time_modal_location": {"code": "class ModalLocationWithCaching:\n    def time_modal_location(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.ModalLocationWithCaching.time_modal_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.ModalLocationWithCaching.track_modal_location_cost": {"code": "class ModalLocationWithCaching:\n    def track_modal_location_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "name": "benchmarks.ModalLocationWithCaching.track_modal_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalLocationEventsSuite.time_total_location_events": {"code": "class TotalLocationEventsSuite:\n    def time_total_location_events(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalLocationEventsSuite.time_total_location_events", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost": {"code": "class TotalLocationEventsSuite:\n    def track_total_location_events_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}}, "machines": {"tomte": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "ram": "131746656", "version": 1}}, "tags": {"0.0.1": 4, "0.0.2": 16, "0.0.3": 260, "0.0.4": 463, "0.0.5": 640, "0.1.0": 1021, "0.1.1": 1095, "0.1.2": 1103, "0.2.0": 1159, "0.2.1": 1221, "0.2.2": 1298, "0.3.0": 1598, "0.4.0": 2547, "0.4.1": 2622, "0.4.2": 2636, "0.4.3": 2821, "0.5.0": 3317}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}