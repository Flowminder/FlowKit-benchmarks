{"project": "FlowKit", "project_url": "https://github.com/Flowminder/FlowKit", "show_commit_url": "https://github.com/Flowminder/FlowKit/commit/", "hash_length": 8, "revision_to_hash": {"4": "a5c731e23308928c75b5267535280aab0c7e4bf7", "16": "2ca58e1d7cdaf14c8f8f2aed545cf961acbde5c0", "260": "bf9d1ae891afe9def7406b6922931a8d16017b56", "463": "251e3977decb56c2e6a78fbee21ac57aed2b31c3", "634": "fa5a5dc823aa4292b6117aee25c7413556d2f55f", "1015": "f51abc5156fcf4815f0ff6d46ac32bf68d535fa9", "1089": "2ece3e59ffcba344f056469ebd51a005f2f95159", "1097": "1249570256e017e91eee51b23d9cdbe516a5c84c", "1153": "48b2df56923ae1cb200a7f5c97dad095c7f57ff6", "1215": "2b3b912095cc44119eb3d8597662737aa827ea9c", "1292": "91d09988496d81968032cda244e0cc1bed24f814", "1361": "d03096a0ca9b89972d02dc2e9e71c3f50963f5bf", "1364": "6776a308c9f575441333a3a2dfafc7a441568893", "1366": "d42159e39d8c9dfefa8d454455bb74c986b929dc", "1397": "7adffdf661980f4783a2ae5b4bdfb21d737cd7dd", "1414": "24f28700b3ae8afdb9c4b5490b41cbfaa337b8f4", "1483": "f5d55d88a2aa2db5539655cac243ec805f5eb446", "1592": "97013831cc176f7e7284c2e413caff901835bee1", "1593": "b73d67a8f5e84662d28a6e382af3038dbf6f0765", "1606": "b01b3d236b075d3ab9a72f925fd7f816d147388b", "2213": "f4dd8af791fab7532bbf41124c95f82d989cfb6c", "2302": "81e54ef05eb0d26fe0dd99ee74273e6722981cb2", "2312": "6d97ee7859d7845de0b8c2ec546af76ef7e53ea1", "2317": "f798f86617bd3680fd187c2fd2acaaa610b99e81", "2320": "4030a7f8fa00c481011d02e2e1ea5b5d95c1c09b", "2376": "73dbf663bab467d16d6ed9d0a2b9086ed9c9d1fc", "2452": "06f10a59680c0ab8eff05aaec916bb539b441f65", "2466": "f3da415dd1e1a184cf38f4e95a80eed75be1a5c6", "2479": "343f829e9f4383c889579ff0418f8418470e6265", "2486": "e18604361454ace228a4656d40bdaa6728fcf86f", "2537": "bc9474bd14e3f590d31e059b823e5794524456d7", "2557": "ca83f279a29adc5faf36f3831a78f6dfa3238042", "2571": "6aea272f8c7faabe89d2ae8c226c9ab1bf61ec30", "2584": "799a950e8324fc857cf0c44959f3cc4a6c964dd5", "2598": "96051c4efc13889a52539f449acfb7508d2cfaa6", "2606": "79a5cf438ce982159ef7a499ce8f55ea4d8faba0", "2619": "f413d1cf5cbc2a716640c0163ffcab9cff37b2eb", "2628": "d2aba155e3ac0a164021742d6607a491e543106d", "2656": "b8eeb053ca37017087d6938e13ac660fc7b22600", "2683": "a7bbfe97fbce28e03d6fbb5faaf6495b050ee27b", "2736": "be1c5ea7325ad4c4d0f5522cc29341c2782b8410", "2757": "626a4bcf4205ef6fdaaa6ac49d6bde7056e02575", "2763": "19919e065249bbc0fb95714824c73513a81b8e35", "2766": "fb1b85a3d1633e637c43907ddf033265733a6f6c", "2774": "49e9fb75dda8cb30a71e39211b84dc3448d2e7f5", "3261": "131c64ece8588da3bec6528405dd057d74aaaf96", "3270": "06c639c8d70b059fc0cb79d664b197868e080387", "3306": "819b340beca607406de747f8b6d99b4be941d2c0", "3338": "7c4247a7551dd7bf425ed03f9633e99d0a5494cc", "3450": "8ad6b2503358f7424b5333f148734287cec12dce", "3469": "e30a6dd95425f11648ca1fb4408964702392ebfa", "3479": "57aeec6ee6b338ba717b0357b6fe8fa1434b8b46", "3520": "9c65ef8e0f18d65eca92bec2ff8976d172b66c08", "3546": "5c283c619e8a3b2715698e95781ee8dd402c223d", "3559": "03ccb9ec747657e2644b2c370c4edf6ad52bbdf7", "3569": "a030995aa74b5744a54e605048162e36705e8716", "3572": "5adf2f1a430ee973ee4fc5085c0591642c60f114", "3601": "afee24bfc41e01ab2bc63c616b7b5e196a8421ff", "3668": "075bb7a195ffa5e6ea9fd320e7a558aeccaf0260", "3694": "52ea91e10a2f89bbda4e776fe99228d1a7632d90", "3706": "89851e2c9198e2f2d6378cd810b14cac9e969582", "3726": "85768d98b1aa146db2dc7895fa54c6c28b422d7c", "3768": "60955876d463fbb9a74c262bf122dfee34762ce9", "3796": "93151b3d55d8bdd5d278220ce5bdac769341066f", "3826": "9a653a314a0aa7ab50af6822f72c91b44c4adc10", "3851": "8a160861bb686ebbe2e284f15a1813fead158ce2", "3861": "c838f6d1ff27585a11a0766344c391487197ee66", "3863": "ba2bfd5d6215a98c334ee3cf6fda2d3d00866531", "3948": "69df744fce8fe8f75d9d4fd52c2dcb5a8d29a45a", "3957": "c85349878b1968c367f69ae19484c788efa8ea3a", "3974": "81b1b7cb61b06f06f38e6a4b6d6bb3d082571d46", "3998": "22b194a91f6aa1742fa69efa2d60e8574041fc4b", "4012": "2fcf95f2e4afec8978840698594fe7b4c2d6cddd", "4015": "93f5f1e7bf58d6e20b9a38e8ffe0c32f154e14ed", "4064": "0632cb824e4bf0c45202a659df3ae55661132676", "4100": "609822b192cbcd99802e1e180f8e39106ae7b8a4", "4130": "f92262ed3daa22998f6c73db669aaca811150805", "4166": "fc6ba1ec2e947057e06ef649028141469f4147e9", "4179": "841bb0aeb2a59a5a64ebc9fabf785f07e80de9ca", "4184": "84967d14d035f02f0c130226415655f891e4c40b", "4189": "ddc23ee97d12275c1acaddf479360d91f822b504", "4192": "22f846f49f7993d77f267395176e63328821155e", "4232": "db21526ff40b57ecb44dcd3df22f77fc5bb31f83", "4352": "2a09b5039eecbd8e061277478078cd1c40e8727c", "4461": "a24b9d922464fe924466bf157646d0d39056d79e", "4512": "00bc877c729510cdc46c14b08ba66fa313db3ce5", "4611": "53d41456761f583e98adc2cedab8a40e655adf75", "4681": "164fab7b36bc0a61b0849c631959dc3e51b44f4f", "4733": "97c01be93ed5f1dbe8c091a1ea5ac2715b8d8c9e", "4836": "ec896b300710e5eb3aa02d5eea32d0792d336354", "4873": "9b25aaacd294c9bbb3d18d889bf325bfeb957ea0", "4881": "90de5812f0c4dae5d1773f030440a5030612fc60", "4921": "bc32e37c295d0068191e4d2f2d84fee8f6f701af", "5037": "9c29a7d0dca83ce55c3d06e9ffec06765b12389c", "5061": "b01bb870c1242f6b98494dc33373f02aab380289", "5152": "a66b4eb9ee18d4186f088511cd7f1a75181a5b7a", "5210": "3089f3644197e63f627f3c9ed1b9b8cbda44c4cc", "5290": "f86f6bb62042cbf4acf4e6cf1f2c4b54d3cfe2c9", "5305": "0ebcfaadc8696719f487ea25077610c61c528b37", "5343": "76098f8d025649737cbdd5a7b308e73b81b7ceec", "5355": "c376861c146088b7003ef41fbcd32e6bba9194dc", "5365": "650ffa0f9aa363c86f4887ebd7dd4c82afb43854", "5396": "b06f039269877fde2cd6665a0b535e65372cd5d2", "5440": "fc0f5fae83a605a710f2affdaaf70d790d1bb776", "5476": "4878903e4a3f4b18a6e0288c25576278ebbcf1a0", "5498": "c7d9e249d5fb3d08e502c488b717ebfc42afb666", "5565": "9b6b51ed09d97ab6547844ed6dba297bb62c84ce", "5573": "467bb10d437ac4a7b88a11453b501ad9e20fd634", "5576": "6cad4ca43640f6c6c45a235b607367dabfdfbcd9", "5594": "6e0eac54df6275ccec4229cda7407d37ac0b8d79", "5608": "6bf20b2d8d4f0ffce537a019614f15c1d468d162", "5633": "5a45397ba5497e681df8210c78c1068e10e816df", "5636": "fe8df9c971d9926362a014b2ddef9d6ef6788d1a", "5659": "cd594f6ba331e8a4eccdb6f1ab9342f2023aa39d", "5705": "f8f60303967ebfe6c651d1a32380d49f3a903e21", "5747": "76d58646138c41147b5baf23e54ea4bb64b79185", "5752": "37ae5916b0bb4cde863753fa95731e54723cab3b", "5827": "9b6efcf1639c5b5ec9287fcf6ff5469a1db89086", "5833": "cef872e1d84be4b1b43833adcc07d18a8a64690c", "5861": "db9510d297dc47e044ff3ee94921698d36a266f4", "5921": "9736caf429cad2a13ab68a17a7da4ad370cd4032", "5929": "05ba372ac2b1a57e20bb9b4140e04de677d64aeb", "6019": "94eb18f5fc33aaed8f591833e19e7340b62410b5", "6046": "32289e1ad97f1a6ab7559e442b0a4a528d1efce6", "6068": "cb1959f2305028b45eb3a60c569d8be3438cb2cf", "6091": "a0536e41577be6babcc3e347343e3be4932d22ab", "6130": "849321b6b9de2b5901495ca9812bc64025162877", "6154": "0c6a349a9c63e89f16a26c15068b620b423b3940", "6191": "4c99bdfb89377c355c8bab3d9e7d1401c8f0fa54", "6207": "14d8c650106f534842d4bf8948ba0d37e1ad403d", "6222": "1f3074a0a860b6f331ddb008f86bb987a395e046", "6242": "4bd28c461fc2f04ba48719dcb3e56a8b9cdfa461", "6256": "48e4e10802b8e94feed32c3fe1e710e626e14a4a", "6278": "895854a026d1d1828946a5f7a8e121eca8d2d92a", "6342": "27cd1d6d76bb6a32b05f636f21f618264923a27d", "6353": "504b53562aa7f8679b2fc4a09dbff99e95beec82", "6367": "02fdcc5e8335d7a12d7fb982beebca302d78656d", "6375": "151894e5dc053c7cf69c3c5a66603ac8da813425", "6414": "82b451c1a58edbe78dc3d7d6e472119c03128794", "6422": "6b134b0c2b601a0202762cbe0c32a1c15686bae5", "6436": "9978425e62233ce6b4d3054938e5e3431f4ed153", "6462": "59f4e0336f4944c5a72283d6380a4899ae3d505d", "6497": "fc48d5057055ec450b07319b6720a62be2461bff", "6520": "21d1a472a631b96ba2931f6776f326efcaf66748", "6522": "46b60facd0e6218432f2b0a833af7ddd0a564005", "6551": "dde846dde28c2fa3cdcae14a5ea84f097801d748", "6565": "c3333aa0f1a0fb8aa294c00b2100dab5a12f46c8", "6580": "35be31ad01d6b45550bd0b1ce46c80aa0d2d7017", "6604": "02e4423a4d86381caa610f1932bd212b3868922e", "6629": "6bfdddd9d62493a39345088169329791fdc9eeb7", "6650": "19d39735a7c63db2f774d1100f884e6f4d68a24b", "6693": "82605091967dea0abb6d5a82c3d41b62c9b0261b"}, "revision_to_date": {"4": 1541031481000, "16": 1541087949000, "260": 1541703719000, "463": 1543252162000, "634": 1544098755000, "1015": 1547543855000, "1089": 1547646794000, "1097": 1547652761000, "1153": 1547657857000, "1215": 1547724887000, "1292": 1547760280000, "1361": 1548218319000, "1364": 1548220081000, "1366": 1548220851000, "1397": 1548268741000, "1414": 1548339523000, "1483": 1548676131000, "1592": 1548928569000, "1593": 1548929830000, "1606": 1548937596000, "2213": 1551351987000, "2302": 1551736605000, "2312": 1551785643000, "2317": 1551790073000, "2320": 1551790437000, "2376": 1551846540000, "2452": 1551914548000, "2466": 1551960956000, "2479": 1552160824000, "2486": 1552303388000, "2537": 1552325793000, "2557": 1552391768000, "2571": 1552397399000, "2584": 1552413329000, "2598": 1552517051000, "2606": 1552559446000, "2619": 1552667101000, "2628": 1552762910000, "2656": 1552767049000, "2683": 1552909352000, "2736": 1553205140000, "2757": 1553276739000, "2763": 1553511299000, "2766": 1553598533000, "2774": 1553600855000, "3261": 1553814046000, "3270": 1553835135000, "3306": 1554069274000, "3338": 1554126780000, "3450": 1554233063000, "3469": 1554297581000, "3479": 1554306850000, "3520": 1554404653000, "3546": 1554475836000, "3559": 1554588618000, "3569": 1554725995000, "3572": 1554805598000, "3601": 1554892481000, "3668": 1555017982000, "3694": 1555094912000, "3706": 1555270186000, "3726": 1555331885000, "3768": 1555358968000, "3796": 1555441635000, "3826": 1555518070000, "3851": 1555604830000, "3861": 1555694370000, "3863": 1555898457000, "3948": 1556045235000, "3957": 1556100527000, "3974": 1556106380000, "3998": 1556128131000, "4012": 1556210310000, "4015": 1556265487000, "4064": 1556545764000, "4100": 1556641400000, "4130": 1556714527000, "4166": 1556830350000, "4179": 1556878853000, "4184": 1556986678000, "4189": 1557115185000, "4192": 1557218724000, "4232": 1557234716000, "4352": 1557356165000, "4461": 1557431446000, "4512": 1557497708000, "4611": 1557763392000, "4681": 1557857248000, "4733": 1557935869000, "4836": 1558031785000, "4873": 1558114469000, "4881": 1558131043000, "4921": 1558360893000, "5037": 1558558386000, "5061": 1558619987000, "5152": 1559055219000, "5210": 1559142658000, "5290": 1559601707000, "5305": 1559646147000, "5343": 1559666877000, "5355": 1559750569000, "5365": 1559810731000, "5396": 1559914301000, "5440": 1560180319000, "5476": 1560274850000, "5498": 1560352214000, "5565": 1560464190000, "5573": 1560525150000, "5576": 1560645461000, "5594": 1560808479000, "5608": 1560872391000, "5633": 1560957142000, "5636": 1561024310000, "5659": 1561130005000, "5705": 1561409806000, "5747": 1561503230000, "5752": 1561545152000, "5827": 1561673552000, "5833": 1561694432000, "5861": 1561808953000, "5921": 1561999703000, "5929": 1562038378000, "6019": 1562177326000, "6046": 1562260776000, "6068": 1562332643000, "6091": 1562589138000, "6130": 1562684739000, "6154": 1562769841000, "6191": 1562884858000, "6207": 1562945228000, "6222": 1563180897000, "6242": 1563543936000, "6256": 1563748132000, "6278": 1563826517000, "6342": 1564414897000, "6353": 1564507242000, "6367": 1564592420000, "6375": 1564659161000, "6414": 1565001288000, "6422": 1565080936000, "6436": 1565090413000, "6462": 1565190451000, "6497": 1565294953000, "6520": 1565446032000, "6522": 1565560178000, "6551": 1565627304000, "6565": 1565811188000, "6580": 1565890858000, "6604": 1565988641000, "6629": 1566229285000, "6650": 1566341552000, "6693": 1566402843000}, "params": {"/home/jamesharrison/synthie": ["", null], "arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz"], "docker": [""], "halo": [""], "machine": ["tomte"], "os": ["Linux 3.10.0-693.21.1.el7.x86_64"], "python": ["3.7"], "ram": ["131746656"], "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": ["", null], "branch": ["master"]}, "graph_param_list": [{"/home/jamesharrison/synthie": "", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": null}, {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "/home/jamesharrison/synthie": null}], "benchmarks": {"benchmarks.AggregateDailyLocation.time_query": {"code": "class AggregateDailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateDailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateDailyLocation.track_cost": {"code": "class AggregateDailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateDailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateModalLocation.time_query": {"code": "class AggregateModalLocation:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateModalLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateModalLocation.track_cost": {"code": "class AggregateModalLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateModalLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateNetworkObjectsSuite.time_query": {"code": "class AggregateNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=\"minute\",\n            spatial_unit=make_spatial_unit(\"admin\", level=3),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateNetworkObjectsSuite.track_cost": {"code": "class AggregateNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=\"minute\",\n            spatial_unit=make_spatial_unit(\"admin\", level=3),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DFSTotalMetricAmountSuite.time_query": {"code": "class DFSTotalMetricAmountSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DFSTotalMetricAmountSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DFSTotalMetricAmountSuite.track_cost": {"code": "class DFSTotalMetricAmountSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.DFSTotalMetricAmountSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DailyLocation.time_query": {"code": "class DailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DailyLocation.track_cost": {"code": "class DailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "name": "benchmarks.DailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.EventScoreSuite.time_query": {"code": "class EventScoreSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=spatial_unit,\n            hours=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.EventScoreSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.EventScoreSuite.track_cost": {"code": "class EventScoreSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=spatial_unit,\n            hours=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.EventScoreSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.FlowSuite.time_query": {"code": "class FlowSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.FlowSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.FlowSuite.track_cost": {"code": "class FlowSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "name": "benchmarks.FlowSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.HartiganClusterSuite.time_query": {"code": "class HartiganClusterSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.HartiganClusterSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.HartiganClusterSuite.track_cost": {"code": "class HartiganClusterSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.HartiganClusterSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.LocationIntroversionSuite.time_query": {"code": "class LocationIntroversionSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, direction=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.LocationIntroversionSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["'in'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.LocationIntroversionSuite.track_cost": {"code": "class LocationIntroversionSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, direction=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.LocationIntroversionSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["'in'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsAggregateSuite.time_query": {"code": "class MeaningfulLocationsAggregateSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, spatial_unit=spatial_unit\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsAggregateSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsAggregateSuite.track_cost": {"code": "class MeaningfulLocationsAggregateSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, spatial_unit=spatial_unit\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsAggregateSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsODSuite.time_query": {"code": "class MeaningfulLocationsODSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-04\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1,\n            meaningful_locations_b=ml2,\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsODSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsODSuite.track_cost": {"code": "class MeaningfulLocationsODSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-04\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1,\n            meaningful_locations_b=ml2,\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsODSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsSuite.time_query": {"code": "class MeaningfulLocationsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=make_spatial_unit(\"versioned-site\"),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsSuite.track_cost": {"code": "class MeaningfulLocationsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=make_spatial_unit(\"versioned-site\"),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.ModalLocationWithCaching.time_query": {"code": "class ModalLocationWithCaching:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.ModalLocationWithCaching.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1800, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.ModalLocationWithCaching.track_cost": {"code": "class ModalLocationWithCaching:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "name": "benchmarks.ModalLocationWithCaching.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "timeout": 1800, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.RadiusOfGyrationSuite.time_query": {"code": "class RadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.RadiusOfGyrationSuite.time_query", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.RadiusOfGyrationSuite.track_cost": {"code": "class RadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "name": "benchmarks.RadiusOfGyrationSuite.track_cost", "param_names": [], "params": [], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalLocationEventsSuite.time_query": {"code": "class TotalLocationEventsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-3]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            spatial_unit=spatial_unit,\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalLocationEventsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["'day'", "'min'"], ["'out'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalLocationEventsSuite.track_cost": {"code": "class TotalLocationEventsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-3]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            spatial_unit=spatial_unit,\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalLocationEventsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["'day'", "'min'"], ["'out'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalNetworkObjectsSuite.time_query": {"code": "class TotalNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-1]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=make_spatial_unit(args[-2]),\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "spatial_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["{'spatial_unit_type': 'admin', 'level': 0}", "{'spatial_unit_type': 'admin', 'level': 3}"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalNetworkObjectsSuite.track_cost": {"code": "class TotalNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-1]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=make_spatial_unit(args[-2]),\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "spatial_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["{'spatial_unit_type': 'admin', 'level': 0}", "{'spatial_unit_type': 'admin', 'level': 3}"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.UniqueSubscriberCountsSuite.time_query": {"code": "class UniqueSubscriberCountsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, hours=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.UniqueSubscriberCountsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.UniqueSubscriberCountsSuite.track_cost": {"code": "class UniqueSubscriberCountsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, hours=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.UniqueSubscriberCountsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}}, "machines": {"tomte": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "ram": "131746656", "version": 1}}, "tags": {"0.0.1": 4, "0.0.2": 16, "0.0.3": 260, "0.0.4": 463, "0.0.5": 634, "0.1.0": 1015, "0.1.1": 1089, "0.1.2": 1097, "0.2.0": 1153, "0.2.1": 1215, "0.2.2": 1292, "0.3.0": 1592, "0.4.0": 2486, "0.4.1": 2557, "0.4.2": 2571, "0.4.3": 2766, "0.5.0": 3261, "0.5.1": 3469, "0.5.2": 3520, "0.5.3": 3726, "0.6.0": 3957, "0.6.1": 3974, "0.6.2": 4130, "0.6.3": 4873, "0.6.4": 5305, "0.7.0": 5921, "0.8.0": 6422}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}