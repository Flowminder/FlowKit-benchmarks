{"project": "FlowKit", "project_url": "https://github.com/Flowminder/FlowKit", "show_commit_url": "https://github.com/Flowminder/FlowKit/commit/", "hash_length": 8, "revision_to_hash": {"4": "a5c731e23308928c75b5267535280aab0c7e4bf7", "16": "2ca58e1d7cdaf14c8f8f2aed545cf961acbde5c0", "260": "bf9d1ae891afe9def7406b6922931a8d16017b56", "463": "251e3977decb56c2e6a78fbee21ac57aed2b31c3", "634": "fa5a5dc823aa4292b6117aee25c7413556d2f55f", "1015": "f51abc5156fcf4815f0ff6d46ac32bf68d535fa9", "1089": "2ece3e59ffcba344f056469ebd51a005f2f95159", "1097": "1249570256e017e91eee51b23d9cdbe516a5c84c", "1153": "48b2df56923ae1cb200a7f5c97dad095c7f57ff6", "1215": "2b3b912095cc44119eb3d8597662737aa827ea9c", "1292": "91d09988496d81968032cda244e0cc1bed24f814", "1361": "d03096a0ca9b89972d02dc2e9e71c3f50963f5bf", "1364": "6776a308c9f575441333a3a2dfafc7a441568893", "1366": "d42159e39d8c9dfefa8d454455bb74c986b929dc", "1397": "7adffdf661980f4783a2ae5b4bdfb21d737cd7dd", "1414": "24f28700b3ae8afdb9c4b5490b41cbfaa337b8f4", "1483": "f5d55d88a2aa2db5539655cac243ec805f5eb446", "1592": "97013831cc176f7e7284c2e413caff901835bee1", "1593": "b73d67a8f5e84662d28a6e382af3038dbf6f0765", "1606": "b01b3d236b075d3ab9a72f925fd7f816d147388b", "2213": "f4dd8af791fab7532bbf41124c95f82d989cfb6c", "2302": "81e54ef05eb0d26fe0dd99ee74273e6722981cb2", "2312": "6d97ee7859d7845de0b8c2ec546af76ef7e53ea1", "2317": "f798f86617bd3680fd187c2fd2acaaa610b99e81", "2320": "4030a7f8fa00c481011d02e2e1ea5b5d95c1c09b", "2376": "73dbf663bab467d16d6ed9d0a2b9086ed9c9d1fc", "2452": "06f10a59680c0ab8eff05aaec916bb539b441f65", "2466": "f3da415dd1e1a184cf38f4e95a80eed75be1a5c6", "2479": "343f829e9f4383c889579ff0418f8418470e6265", "2486": "e18604361454ace228a4656d40bdaa6728fcf86f", "2537": "bc9474bd14e3f590d31e059b823e5794524456d7", "2557": "ca83f279a29adc5faf36f3831a78f6dfa3238042", "2571": "6aea272f8c7faabe89d2ae8c226c9ab1bf61ec30", "2584": "799a950e8324fc857cf0c44959f3cc4a6c964dd5", "2598": "96051c4efc13889a52539f449acfb7508d2cfaa6", "2606": "79a5cf438ce982159ef7a499ce8f55ea4d8faba0", "2619": "f413d1cf5cbc2a716640c0163ffcab9cff37b2eb", "2628": "d2aba155e3ac0a164021742d6607a491e543106d", "2656": "b8eeb053ca37017087d6938e13ac660fc7b22600", "2683": "a7bbfe97fbce28e03d6fbb5faaf6495b050ee27b", "2736": "be1c5ea7325ad4c4d0f5522cc29341c2782b8410", "2757": "626a4bcf4205ef6fdaaa6ac49d6bde7056e02575", "2763": "19919e065249bbc0fb95714824c73513a81b8e35", "2766": "fb1b85a3d1633e637c43907ddf033265733a6f6c", "2774": "49e9fb75dda8cb30a71e39211b84dc3448d2e7f5", "3261": "131c64ece8588da3bec6528405dd057d74aaaf96", "3270": "06c639c8d70b059fc0cb79d664b197868e080387", "3306": "819b340beca607406de747f8b6d99b4be941d2c0", "3338": "7c4247a7551dd7bf425ed03f9633e99d0a5494cc", "3450": "8ad6b2503358f7424b5333f148734287cec12dce", "3469": "e30a6dd95425f11648ca1fb4408964702392ebfa", "3479": "57aeec6ee6b338ba717b0357b6fe8fa1434b8b46", "3520": "9c65ef8e0f18d65eca92bec2ff8976d172b66c08", "3546": "5c283c619e8a3b2715698e95781ee8dd402c223d", "3559": "03ccb9ec747657e2644b2c370c4edf6ad52bbdf7", "3569": "a030995aa74b5744a54e605048162e36705e8716", "3572": "5adf2f1a430ee973ee4fc5085c0591642c60f114", "3601": "afee24bfc41e01ab2bc63c616b7b5e196a8421ff", "3668": "075bb7a195ffa5e6ea9fd320e7a558aeccaf0260", "3694": "52ea91e10a2f89bbda4e776fe99228d1a7632d90", "3706": "89851e2c9198e2f2d6378cd810b14cac9e969582", "3726": "85768d98b1aa146db2dc7895fa54c6c28b422d7c", "3768": "60955876d463fbb9a74c262bf122dfee34762ce9", "3796": "93151b3d55d8bdd5d278220ce5bdac769341066f", "3826": "9a653a314a0aa7ab50af6822f72c91b44c4adc10", "3851": "8a160861bb686ebbe2e284f15a1813fead158ce2", "3861": "c838f6d1ff27585a11a0766344c391487197ee66", "3863": "ba2bfd5d6215a98c334ee3cf6fda2d3d00866531", "3948": "69df744fce8fe8f75d9d4fd52c2dcb5a8d29a45a", "3957": "c85349878b1968c367f69ae19484c788efa8ea3a", "3974": "81b1b7cb61b06f06f38e6a4b6d6bb3d082571d46", "3998": "22b194a91f6aa1742fa69efa2d60e8574041fc4b", "4012": "2fcf95f2e4afec8978840698594fe7b4c2d6cddd", "4015": "93f5f1e7bf58d6e20b9a38e8ffe0c32f154e14ed", "4064": "0632cb824e4bf0c45202a659df3ae55661132676", "4100": "609822b192cbcd99802e1e180f8e39106ae7b8a4", "4130": "f92262ed3daa22998f6c73db669aaca811150805", "4166": "fc6ba1ec2e947057e06ef649028141469f4147e9", "4179": "841bb0aeb2a59a5a64ebc9fabf785f07e80de9ca", "4184": "84967d14d035f02f0c130226415655f891e4c40b", "4189": "ddc23ee97d12275c1acaddf479360d91f822b504", "4192": "22f846f49f7993d77f267395176e63328821155e", "4232": "db21526ff40b57ecb44dcd3df22f77fc5bb31f83", "4352": "2a09b5039eecbd8e061277478078cd1c40e8727c", "4461": "a24b9d922464fe924466bf157646d0d39056d79e", "4512": "00bc877c729510cdc46c14b08ba66fa313db3ce5", "4611": "53d41456761f583e98adc2cedab8a40e655adf75", "4681": "164fab7b36bc0a61b0849c631959dc3e51b44f4f", "4733": "97c01be93ed5f1dbe8c091a1ea5ac2715b8d8c9e", "4836": "ec896b300710e5eb3aa02d5eea32d0792d336354", "4873": "9b25aaacd294c9bbb3d18d889bf325bfeb957ea0", "4881": "90de5812f0c4dae5d1773f030440a5030612fc60", "4921": "bc32e37c295d0068191e4d2f2d84fee8f6f701af", "5037": "9c29a7d0dca83ce55c3d06e9ffec06765b12389c", "5061": "b01bb870c1242f6b98494dc33373f02aab380289", "5152": "a66b4eb9ee18d4186f088511cd7f1a75181a5b7a", "5210": "3089f3644197e63f627f3c9ed1b9b8cbda44c4cc", "5290": "f86f6bb62042cbf4acf4e6cf1f2c4b54d3cfe2c9", "5305": "0ebcfaadc8696719f487ea25077610c61c528b37", "5343": "76098f8d025649737cbdd5a7b308e73b81b7ceec", "5355": "c376861c146088b7003ef41fbcd32e6bba9194dc", "5365": "650ffa0f9aa363c86f4887ebd7dd4c82afb43854", "5396": "b06f039269877fde2cd6665a0b535e65372cd5d2", "5440": "fc0f5fae83a605a710f2affdaaf70d790d1bb776", "5476": "4878903e4a3f4b18a6e0288c25576278ebbcf1a0", "5498": "c7d9e249d5fb3d08e502c488b717ebfc42afb666", "5565": "9b6b51ed09d97ab6547844ed6dba297bb62c84ce", "5573": "467bb10d437ac4a7b88a11453b501ad9e20fd634", "5576": "6cad4ca43640f6c6c45a235b607367dabfdfbcd9", "5594": "6e0eac54df6275ccec4229cda7407d37ac0b8d79", "5608": "6bf20b2d8d4f0ffce537a019614f15c1d468d162", "5633": "5a45397ba5497e681df8210c78c1068e10e816df", "5636": "fe8df9c971d9926362a014b2ddef9d6ef6788d1a", "5659": "cd594f6ba331e8a4eccdb6f1ab9342f2023aa39d", "5705": "f8f60303967ebfe6c651d1a32380d49f3a903e21", "5747": "76d58646138c41147b5baf23e54ea4bb64b79185", "5752": "37ae5916b0bb4cde863753fa95731e54723cab3b", "5827": "9b6efcf1639c5b5ec9287fcf6ff5469a1db89086", "5833": "cef872e1d84be4b1b43833adcc07d18a8a64690c", "5861": "db9510d297dc47e044ff3ee94921698d36a266f4", "5921": "9736caf429cad2a13ab68a17a7da4ad370cd4032", "5929": "05ba372ac2b1a57e20bb9b4140e04de677d64aeb", "6019": "94eb18f5fc33aaed8f591833e19e7340b62410b5", "6046": "32289e1ad97f1a6ab7559e442b0a4a528d1efce6", "6068": "cb1959f2305028b45eb3a60c569d8be3438cb2cf", "6091": "a0536e41577be6babcc3e347343e3be4932d22ab", "6130": "849321b6b9de2b5901495ca9812bc64025162877", "6154": "0c6a349a9c63e89f16a26c15068b620b423b3940", "6191": "4c99bdfb89377c355c8bab3d9e7d1401c8f0fa54", "6207": "14d8c650106f534842d4bf8948ba0d37e1ad403d", "6222": "1f3074a0a860b6f331ddb008f86bb987a395e046", "6241": "4bd28c461fc2f04ba48719dcb3e56a8b9cdfa461", "6249": "48e4e10802b8e94feed32c3fe1e710e626e14a4a", "6265": "895854a026d1d1828946a5f7a8e121eca8d2d92a", "6293": "27cd1d6d76bb6a32b05f636f21f618264923a27d", "6301": "504b53562aa7f8679b2fc4a09dbff99e95beec82", "6308": "02fdcc5e8335d7a12d7fb982beebca302d78656d", "6314": "151894e5dc053c7cf69c3c5a66603ac8da813425", "6341": "82b451c1a58edbe78dc3d7d6e472119c03128794", "6345": "6b134b0c2b601a0202762cbe0c32a1c15686bae5", "6354": "9978425e62233ce6b4d3054938e5e3431f4ed153", "6376": "59f4e0336f4944c5a72283d6380a4899ae3d505d", "6403": "fc48d5057055ec450b07319b6720a62be2461bff", "6424": "21d1a472a631b96ba2931f6776f326efcaf66748", "6426": "46b60facd0e6218432f2b0a833af7ddd0a564005", "6449": "dde846dde28c2fa3cdcae14a5ea84f097801d748", "6460": "c3333aa0f1a0fb8aa294c00b2100dab5a12f46c8", "6475": "35be31ad01d6b45550bd0b1ce46c80aa0d2d7017", "6499": "02e4423a4d86381caa610f1932bd212b3868922e", "6524": "6bfdddd9d62493a39345088169329791fdc9eeb7", "6545": "19d39735a7c63db2f774d1100f884e6f4d68a24b", "6584": "82605091967dea0abb6d5a82c3d41b62c9b0261b", "6617": "2fc8032a7e001ff3916c3558804a9233f0d0e516", "6624": "eb88991c46be3d7dadad4518f1ea7961780ed0b1", "6667": "bb729363655b23716c82775901a0c5b9b6aa263c", "6673": "2bb550a7e5eb4294c9ca9b938317f379b10d075c", "6709": "cdfe33cc5c8fee1746c86dee6f4150adf8982fc8", "6722": "3fbe325ce449d820e090831df768b2b4d76762dd", "6741": "c7c720fcfeaf25558e85d0576c427cb582be34c5", "6753": "066edefb4579d34f6a311de62ffe2b9b5c505be5", "6773": "07df427c3f3b6e43ee9d106cdfca47105ce4ba37", "6776": "535b4a454043c3ef3d995b7e523236ffc25f056b", "6818": "57a3c476cdcb5b6464cf66f23c495837ac8ec58f", "6825": "ea206500df7ec110aee44666983e9ce91fdbeee0", "6834": "fec104e7cb67a8057447fbc114b4d1921bcfd69b", "6875": "bd5ddee0941ee23369fdad37413e6765f4c2237b", "6916": "e4f96efc39e05db67ccc4f5de544866021f84c4b", "6920": "2317f70c9df6e0288e582e384692043c82025d3e", "6951": "b753ecbd7bf09e4596819b3729c9a40ed5f3ebdd", "7016": "54f4011f64b0eb178713ccaff6392a3e08dce48f", "7045": "1321d048120e86a608b34782467455e90aecffe8", "7074": "b573fd09c7b8d2ee1d403e05d1f963c640c29973", "7116": "6f1592816ebec587aabe23bbac1fdc5c7e0f4f9d", "7120": "bb26f7ad6d43916e3b79e74c16f80425422b50cc", "7140": "afd18400dc74e3180151d382767904f38ffa1055", "7170": "0d8324f070c3bdaccec9a85525241e6c37efce04", "7190": "d669871951d2de65e1623ad06725b2a83d468b31", "7196": "56b5b7adee2406ff6c1b3d32e43e4650507030e4", "7204": "1aa9151da4ad60bea6e9416dd4f3e446a13d686b", "7210": "324523d41359809dcc221262d4a632625ef794b3", "7224": "3ce2e70cf6d9f3b537986c35741632a684c11221", "7229": "870fd315fe461091fca2864e792becb121e4cf35", "7234": "e590b865ee847e5d3c4123efc3411518eba1d4b9", "7238": "9b32298d0b01728453df78ddd604efa59c3da2ce", "7268": "3ad05e360ff085f26b40b125f493942162a452c9", "7276": "250e3d7153af41e48dd15debf3eef42279fbbe08", "7287": "60c2275c9923639f78cb234847ff038ef6ba1ecf", "7294": "971144b22817f18c25e1ac2531a869f5ecbee9f2", "7319": "8d59cb654547583bd42879ef70d4e58839ca4f83", "7337": "faada916a9e2d06d9006e20086e49363b878e758", "7373": "0206aa6961724c2c1e139b2e2c7b1c9ac8dde656", "7386": "1d2fdcd68fd9e06e4fbb3ed2aae34cbe5c1d1fd5", "7401": "f3f8713d468f232870042ed54c2e30f1624baa9c", "7410": "b7ea1e180c6e4bbbbc4dfb68655dc18dc74dae9e", "7414": "439f3c017c3c8ea4fb5465201c1ad61c68f3e241", "7422": "b1a80289070eb6e063699c56e766efd016022a51", "7430": "0f0da4c1344480a8d3a9bd8457a6b11f410f8611", "7432": "bd9523f0536a82c72f968067893df48f69b208c7", "7451": "fe7f2e22821269e485389b119dfbbce651108c21", "7461": "fad1e20b7005c75d69de02d39a19bfc4cb537e6a", "7469": "31815e050422d0798f15d7dd245d962a5b99d832", "7500": "aaa27cf6182b9bce27ed2c0bd4f75caebae31620", "7522": "a0c6bf4055bb95f2a9b7e6a204d35e5d1b85b58c", "7528": "3686a160c6a4b94367b2bc93404dd6d15ee7b2b6", "7556": "08e8ed047201ceecf323cb25c7dc649aee1a5abc", "7558": "b7acbe72e91bc85fa19e0b0a868dbf24a556e29a", "7565": "ef7341d55db5e22109a22ba658efea1290d2de26", "7606": "f0d798afec25c148cee09794a433e0890643e8be", "7650": "b61b1e69378e5fbd9adfb4563ed7ca385dff1ad2", "7664": "979cca923e8cfe812652bfc490183807ff22f5cb", "7884": "ec83f2d99bb2e9ca1d4fb2f7bcd927ae396acf11", "7890": "bb6aa23638787b398db817147acc2ecb0c7f2dcc", "7892": "d45492b6603ee549af90144b0f28b4569aa3107a", "7907": "9783d2899e53eab68f6b579b3c56f4f1069e9e04", "7940": "8040a9710158af4d932179136c2c7fee35169fc3", "7950": "bf5c9eb88f6e064f7368ce9c0e96ec7928f98138", "7964": "f474aa67b8598c2e23ff386e21b88d974fec6c4e", "7980": "273db7839f2fa19265f03287230c0cff68528434", "8005": "26a6f2847bd21d234de6528a3038ff9d669f72cc", "8016": "f31f77704c9615c2826322a40a55b5b93536ebdf", "8049": "6cce10bdbaf55c138c61d9ef3f28bed1cf87d695", "8079": "59fa6a07bab611153fe497a40b6c2e7376b99a6c", "8179": "60bf601b508bdb71812ac1a8657a4b9cc5f33d8f", "8197": "c3453b5aef3009a170abef68d3dc96f406cf98fd", "8227": "f5cb213bb1c3ab56e378495f76a76826933a2ca7", "8265": "4c3e30c8c905784050e428f86a67e4dfafe94564", "8286": "7387d1f867fa199cd79a97f11a73273555436cda", "8385": "17da706bdfa3baed6241d2a3d7111c4b47f3bbc4", "8710": "27a64307f3dc0f08a0ee919f753ddff039368fca", "8730": "618145db78c5e58e082ba9a0746917fdce005961", "8732": "7dca50935da72a8bdda2f6dca20d5578b54e40c8", "8771": "dcd911dfc8154a52f3dd4696245f309ae13ce6b2", "8780": "5b8fa0bc815bc06c4b21f0d62bc50320faf4b6f1", "8783": "17bd20a9b451ac493fc779c05df1b9cde694b14e", "8794": "3fb1dae0baf7364f8e1c40066e561d7d87eedbd2", "8802": "1cb1224de669c84740b45419f41ff08ab0026978", "8804": "0f7f937f455ff97120a8511561951dc0e08452f9", "8814": "85dfae655c044c8597e2994da4320adad5d67d68", "8819": "d5fc15846ba477d0d90ec033dce5b8d4328634a1", "8877": "9ad9b74246b08d462dcc47f0f180139cc47e3538", "8904": "eb5a6e5a857e2a7004529c68489cc9eb7060216f", "8929": "c1a1279ecd91bba6f5acefbb41e426c6530ca88f", "8936": "8167c5e321a7718863d6c1930d94efb612d072f2", "8960": "c267a0a06b31dbd03ad230cdfb65eab1f7865265", "8964": "edd0e895f098c1cf97d89cc754507396d46af775", "8969": "b2e73794eb7ddadcc995543db4be82f747d65f80", "8984": "f1dccbec12d18bbc0b451d381b496fc55120c5a1", "8990": "314a17e14741afa6a41852a323542829cefede10", "9000": "84ff902e8efe0875909bbf63c0f562b983673eac", "9019": "eaef38ba3aabbf249779f143889a86c3049ce829", "9052": "e6f101bc754b694076cd15905d73ae40eba1b676", "9058": "e1defc3c7bfa231d713e4ea507d7555524613141", "9095": "a2f39345421232ccaa1402f448bc467db7628427", "9161": "fd4d94d472cb111515a715ff948fd3ca16e58c19", "9212": "324126e0831e89b9b6a66d74bd30d7943999c7e3", "9240": "4a81116b6c17a9baa3fb0884d255db139d981ae5", "9247": "3e6a432893b6791785359b839ffe074d19398ceb", "9252": "75d0f55248cda38bbf1ab8c21ff51bed59144bcf", "9317": "b6d5f27939f9e9b88bc590d1c85242a25c16ec1b", "9327": "e6e81a5c35648969b91a2148e043398052766c80", "9348": "46f6d72fd5768e58e4781decac3db0e5a3cde3e3", "9364": "ef357a52161db4e666965f376230dcf80c52f1d1", "9380": "f471f9e19849ffc74622cde058599d62694d7dc5", "9391": "22936a0393b6c8e95efead77688f234b0a3e1cc1", "9395": "100eef7d5f309da4d5a414bd855bd3d028d94cc9", "9407": "b56173e5ddcade8d0814bc64c8505a84fdcf4330", "9427": "3d65a760b7ed24d6bd0163a9b67655fb3d03ec3a", "9456": "470e9bde81d8a43c3cb1d05dad4d9a9a4fec94bb", "9482": "f18eb563054d499c1dd54e9ef5845a043b43fef0", "9512": "033c43f48875073e318ececc69bc8b654f196908", "9524": "e9a0e2a8d4d48f34eddeb229772477079b5636af", "9527": "7ab2360d8adab57ed0e607196757475e2582b528", "9531": "a6971ef5676110a19948fbdbee0b2d07ee65d719", "9552": "37c2f88b7b80c85fa4243f9313fc93ec1ab7648f", "9562": "2f76c00fd7e443a21c85d29bf187d371dde7f2fd", "9573": "de738dc3d4a68ed4b5d2ed16c3402c907655eff9", "9577": "42c0535e2ed3ab8983220d00d52acd6aee0fc59f", "9614": "0eafe4a3bcbd01fa5d67deb18c16e4eb74f95618", "9625": "a1215e7ad93f7efc09ab73016a440a1e68b39b8a", "9631": "488b41338cb7a7dd7541a7d353ec7ddec2743f21", "9633": "eb45b8f263f4e38f0dc8243f059cc40e2ad733f9", "9648": "ad78dbe4fa353c5bf951d5eb5ddfebc9674e6a72", "9655": "394004f267257b896d991e670bf15795352c8977", "9665": "68d8ee2bba4613066c6e1c01ec6b0bf63ffd7ac8", "9688": "709052cd976c4d82997c705a84543efd683ac31d", "9696": "3bdaea6c6cb01978b1304d95060c9d1105700383", "9716": "d66ad8b793db3ba08302ac4399793d1a060b51f8", "9755": "876b4d5e247db3eccd62bb7ab8978e08192a4df3", "9773": "601c8c0fc781e6e2d3145df4c91cd1204fad399e", "9781": "a7d55552a2de29bda94841915313ca07eada7e6d", "9831": "d1d486fb0d159911fb5750137b585e444855f52c", "9835": "c014e90dae3fa53adf4aa9963846a8a69e9241cc", "9963": "6d981b9e43d5bfa3d231f869709ee5a374afc45f", "10085": "bdaa77815cf2d00e9f87e6f2f1ad2125ea8019b9", "10087": "ab04c91c198c2bedae382e62a8e031dee801fa56", "10102": "4f30298b7b391e00c6c4b93a633336f80e24150d", "10160": "891819c2b1c0e5ab46fe80fbbfe938f7849bf44d", "10181": "3eeb9521b751241df56fee6dc58e2a1ddbc362ec", "10186": "253c460b5b164f2fd64329eae69b01ff1c86d737", "10199": "a87fa8c8802bb41a488867778e85058708dd0c8d", "10210": "5197e32cb70b655471cf73cece5ed69daac85ef3", "10243": "9eda55075cf9c67ac4152dd493a696d40cc96021", "10284": "2fdeb531b6e145bd45f2a305b821d69360d6f0a1"}, "revision_to_date": {"4": 1541031481000, "16": 1541087949000, "260": 1541703719000, "463": 1543252162000, "634": 1544098755000, "1015": 1547543855000, "1089": 1547646794000, "1097": 1547652761000, "1153": 1547657857000, "1215": 1547724887000, "1292": 1547760280000, "1361": 1548218319000, "1364": 1548220081000, "1366": 1548220851000, "1397": 1548268741000, "1414": 1548339523000, "1483": 1548676131000, "1592": 1548928569000, "1593": 1548929830000, "1606": 1548937596000, "2213": 1551351987000, "2302": 1551736605000, "2312": 1551785643000, "2317": 1551790073000, "2320": 1551790437000, "2376": 1551846540000, "2452": 1551914548000, "2466": 1551960956000, "2479": 1552160824000, "2486": 1552303388000, "2537": 1552325793000, "2557": 1552391768000, "2571": 1552397399000, "2584": 1552413329000, "2598": 1552517051000, "2606": 1552559446000, "2619": 1552667101000, "2628": 1552762910000, "2656": 1552767049000, "2683": 1552909352000, "2736": 1553205140000, "2757": 1553276739000, "2763": 1553511299000, "2766": 1553598533000, "2774": 1553600855000, "3261": 1553814046000, "3270": 1553835135000, "3306": 1554069274000, "3338": 1554126780000, "3450": 1554233063000, "3469": 1554297581000, "3479": 1554306850000, "3520": 1554404653000, "3546": 1554475836000, "3559": 1554588618000, "3569": 1554725995000, "3572": 1554805598000, "3601": 1554892481000, "3668": 1555017982000, "3694": 1555094912000, "3706": 1555270186000, "3726": 1555331885000, "3768": 1555358968000, "3796": 1555441635000, "3826": 1555518070000, "3851": 1555604830000, "3861": 1555694370000, "3863": 1555898457000, "3948": 1556045235000, "3957": 1556100527000, "3974": 1556106380000, "3998": 1556128131000, "4012": 1556210310000, "4015": 1556265487000, "4064": 1556545764000, "4100": 1556641400000, "4130": 1556714527000, "4166": 1556830350000, "4179": 1556878853000, "4184": 1556986678000, "4189": 1557115185000, "4192": 1557218724000, "4232": 1557234716000, "4352": 1557356165000, "4461": 1557431446000, "4512": 1557497708000, "4611": 1557763392000, "4681": 1557857248000, "4733": 1557935869000, "4836": 1558031785000, "4873": 1558114469000, "4881": 1558131043000, "4921": 1558360893000, "5037": 1558558386000, "5061": 1558619987000, "5152": 1559055219000, "5210": 1559142658000, "5290": 1559601707000, "5305": 1559646147000, "5343": 1559666877000, "5355": 1559750569000, "5365": 1559810731000, "5396": 1559914301000, "5440": 1560180319000, "5476": 1560274850000, "5498": 1560352214000, "5565": 1560464190000, "5573": 1560525150000, "5576": 1560645461000, "5594": 1560808479000, "5608": 1560872391000, "5633": 1560957142000, "5636": 1561024310000, "5659": 1561130005000, "5705": 1561409806000, "5747": 1561503230000, "5752": 1561545152000, "5827": 1561673552000, "5833": 1561694432000, "5861": 1561808953000, "5921": 1561999703000, "5929": 1562038378000, "6019": 1562177326000, "6046": 1562260776000, "6068": 1562332643000, "6091": 1562589138000, "6130": 1562684739000, "6154": 1562769841000, "6191": 1562884858000, "6207": 1562945228000, "6222": 1563180897000, "6241": 1563543936000, "6249": 1563748132000, "6265": 1563826517000, "6293": 1564414897000, "6301": 1564507242000, "6308": 1564592420000, "6314": 1564659161000, "6341": 1565001288000, "6345": 1565080936000, "6354": 1565090413000, "6376": 1565190451000, "6403": 1565294953000, "6424": 1565446032000, "6426": 1565560178000, "6449": 1565627304000, "6460": 1565811188000, "6475": 1565890858000, "6499": 1565988641000, "6524": 1566229285000, "6545": 1566341552000, "6584": 1566402843000, "6617": 1566506446000, "6624": 1566845945000, "6667": 1566936365000, "6673": 1566963119000, "6709": 1567200054000, "6722": 1567242519000, "6741": 1567431611000, "6753": 1567538824000, "6773": 1567610380000, "6776": 1567670300000, "6818": 1567818934000, "6825": 1567939259000, "6834": 1568024404000, "6875": 1568210592000, "6916": 1568368325000, "6920": 1568581773000, "6951": 1568657076000, "7016": 1568755902000, "7045": 1568815857000, "7074": 1568893211000, "7116": 1569080645000, "7120": 1569174837000, "7140": 1569243261000, "7170": 1569404510000, "7190": 1569516545000, "7196": 1569622409000, "7204": 1569698490000, "7210": 1569767787000, "7224": 1569848719000, "7229": 1569925335000, "7234": 1569947399000, "7238": 1570044049000, "7268": 1570143095000, "7276": 1570223121000, "7287": 1570291706000, "7294": 1570383315000, "7319": 1570460906000, "7337": 1570574261000, "7373": 1570655673000, "7386": 1570705246000, "7401": 1570801289000, "7410": 1570916174000, "7414": 1570941935000, "7422": 1571065170000, "7430": 1571134932000, "7432": 1571225381000, "7451": 1571339030000, "7461": 1571462812000, "7469": 1571574390000, "7500": 1571651414000, "7522": 1571782548000, "7528": 1571888816000, "7556": 1572032003000, "7558": 1572120919000, "7565": 1572304682000, "7606": 1572354263000, "7650": 1572543755000, "7664": 1572628019000, "7884": 1572904174000, "7890": 1572993824000, "7892": 1573038560000, "7907": 1573303747000, "7940": 1573513668000, "7950": 1573569415000, "7964": 1573667956000, "7980": 1573774023000, "8005": 1573860311000, "8016": 1573869948000, "8049": 1574080201000, "8079": 1574206059000, "8179": 1574357021000, "8197": 1574533876000, "8227": 1574700326000, "8265": 1574794861000, "8286": 1574899016000, "8385": 1574963351000, "8710": 1576153554000, "8730": 1576355939000, "8732": 1576441842000, "8771": 1576525506000, "8780": 1576695031000, "8783": 1576866056000, "8794": 1577032597000, "8802": 1577185453000, "8804": 1577394608000, "8814": 1577476766000, "8819": 1577705303000, "8877": 1577989474000, "8904": 1578351685000, "8929": 1578430267000, "8936": 1578492881000, "8960": 1578604735000, "8964": 1578650540000, "8969": 1578809740000, "8984": 1578930016000, "8990": 1579021139000, "9000": 1579102028000, "9019": 1579175989000, "9052": 1579267601000, "9058": 1579406837000, "9095": 1579556764000, "9161": 1579638908000, "9212": 1579727972000, "9240": 1579810598000, "9247": 1579948872000, "9252": 1580070517000, "9317": 1580154659000, "9327": 1580157598000, "9348": 1580234501000, "9364": 1580325556000, "9380": 1580403705000, "9391": 1580444933000, "9395": 1580524704000, "9407": 1580676174000, "9427": 1580739043000, "9456": 1580827050000, "9482": 1580942259000, "9512": 1581027605000, "9524": 1581083099000, "9527": 1581134262000, "9531": 1581274288000, "9552": 1581334686000, "9562": 1581550928000, "9573": 1581590558000, "9577": 1581593961000, "9614": 1581720249000, "9625": 1581914367000, "9631": 1581943234000, "9633": 1581950638000, "9648": 1582051426000, "9655": 1582142251000, "9665": 1582207119000, "9688": 1582565952000, "9696": 1582636999000, "9716": 1582751737000, "9755": 1582799831000, "9773": 1582905570000, "9781": 1582974384000, "9831": 1583152521000, "9835": 1583171720000, "9963": 1583251115000, "10085": 1583255657000, "10087": 1583320723000, "10102": 1583418333000, "10160": 1583782022000, "10181": 1583851727000, "10186": 1583860329000, "10199": 1583948313000, "10210": 1584043555000, "10243": 1584099724000, "10284": 1584139172000}, "params": {"/home/jamesharrison/synthie": ["", null], "arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz"], "docker": [""], "halo": [""], "machine": ["tomte"], "os": ["Linux 3.10.0-693.21.1.el7.x86_64"], "python": ["3.7"], "ram": ["131746656"], "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": ["", null], "branch": ["master"]}, "graph_param_list": [{"/home/jamesharrison/synthie": "", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": null}, {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "/home/jamesharrison/synthie": null}], "benchmarks": {"benchmarks.AggregateDailyLocation.time_query": {"code": "class AggregateDailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateDailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["True", "False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateDailyLocation.track_cost": {"code": "class AggregateDailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateDailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["True", "False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateModalLocation.time_query": {"code": "class AggregateModalLocation:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateModalLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateModalLocation.track_cost": {"code": "class AggregateModalLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateModalLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateNetworkObjectsSuite.time_query": {"code": "class AggregateNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=\"minute\",\n            spatial_unit=make_spatial_unit(\"admin\", level=3),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateNetworkObjectsSuite.track_cost": {"code": "class AggregateNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=\"minute\",\n            spatial_unit=make_spatial_unit(\"admin\", level=3),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DFSTotalMetricAmountSuite.time_query": {"code": "class DFSTotalMetricAmountSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DFSTotalMetricAmountSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DFSTotalMetricAmountSuite.track_cost": {"code": "class DFSTotalMetricAmountSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.DFSTotalMetricAmountSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DailyLocation.time_query": {"code": "class DailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DailyLocation.track_cost": {"code": "class DailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "name": "benchmarks.DailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.EventScoreSuite.time_query": {"code": "class EventScoreSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=spatial_unit,\n            hours=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.EventScoreSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.EventScoreSuite.track_cost": {"code": "class EventScoreSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=spatial_unit,\n            hours=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.EventScoreSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.FlowSuite.time_query": {"code": "class FlowSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.FlowSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["0", "1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.FlowSuite.track_cost": {"code": "class FlowSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "name": "benchmarks.FlowSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["0", "1", "2"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.HartiganClusterSuite.time_query": {"code": "class HartiganClusterSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = HartiganCluster(\n            calldays=CallDays(\n                SubscriberLocations(\n                    start=\"2016-01-01\",\n                    stop=\"2016-01-07\",\n                    hours=args[-2],\n                    spatial_unit=make_spatial_unit(\"versioned-site\"),\n                )\n            ),\n            radius=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.HartiganClusterSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.HartiganClusterSuite.track_cost": {"code": "class HartiganClusterSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = HartiganCluster(\n            calldays=CallDays(\n                SubscriberLocations(\n                    start=\"2016-01-01\",\n                    stop=\"2016-01-07\",\n                    hours=args[-2],\n                    spatial_unit=make_spatial_unit(\"versioned-site\"),\n                )\n            ),\n            radius=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.HartiganClusterSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.LocationIntroversionSuite.time_query": {"code": "class LocationIntroversionSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, direction=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.LocationIntroversionSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["'in'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.LocationIntroversionSuite.track_cost": {"code": "class LocationIntroversionSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, direction=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.LocationIntroversionSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["'in'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsAggregateSuite.time_query": {"code": "class MeaningfulLocationsAggregateSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-07\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, spatial_unit=spatial_unit\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsAggregateSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsAggregateSuite.track_cost": {"code": "class MeaningfulLocationsAggregateSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-07\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, spatial_unit=spatial_unit\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsAggregateSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsODSuite.time_query": {"code": "class MeaningfulLocationsODSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml1 = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-04\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-04\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-07\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1,\n            meaningful_locations_b=ml2,\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsODSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsODSuite.track_cost": {"code": "class MeaningfulLocationsODSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        ml1 = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-04\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\",\n                stop=\"2016-01-04\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=HartiganCluster(\n                calldays=CallDays(\n                    SubscriberLocations(\n                        start=\"2016-01-01\",\n                        stop=\"2016-01-07\",\n                        spatial_unit=make_spatial_unit(\"versioned-site\"),\n                    )\n                ),\n                radius=1.0,\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\",\n                stop=\"2016-01-07\",\n                spatial_unit=make_spatial_unit(\"versioned-site\"),\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1,\n            meaningful_locations_b=ml2,\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsODSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'admin', 'level': 1}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsSuite.time_query": {"code": "class MeaningfulLocationsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = HartiganCluster(\n            calldays=CallDays(\n                SubscriberLocations(\n                    start=\"2016-01-01\",\n                    stop=\"2016-01-07\",\n                    spatial_unit=make_spatial_unit(\"versioned-site\"),\n                )\n            ),\n            radius=1.0,\n        )\n        es = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=make_spatial_unit(\"versioned-site\"),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'day'", "'unknown'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsSuite.track_cost": {"code": "class MeaningfulLocationsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = HartiganCluster(\n            calldays=CallDays(\n                SubscriberLocations(\n                    start=\"2016-01-01\",\n                    stop=\"2016-01-07\",\n                    spatial_unit=make_spatial_unit(\"versioned-site\"),\n                )\n            ),\n            radius=1.0,\n        )\n        es = EventScore(\n            start=\"2016-01-01\",\n            stop=\"2016-01-07\",\n            spatial_unit=make_spatial_unit(\"versioned-site\"),\n        )\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'day'", "'unknown'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.ModalLocationWithCaching.time_query": {"code": "class ModalLocationWithCaching:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.ModalLocationWithCaching.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["0", "3", "7"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1800, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.ModalLocationWithCaching.track_cost": {"code": "class ModalLocationWithCaching:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "name": "benchmarks.ModalLocationWithCaching.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["0", "3", "7"], ["'last'", "'most-common'"]], "timeout": 1800, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.RadiusOfGyrationSuite.time_query": {"code": "class RadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.RadiusOfGyrationSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.RadiusOfGyrationSuite.track_cost": {"code": "class RadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "name": "benchmarks.RadiusOfGyrationSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalLocationEventsSuite.time_query": {"code": "class TotalLocationEventsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-3]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            spatial_unit=spatial_unit,\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalLocationEventsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["'day'", "'min'"], ["'out'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalLocationEventsSuite.track_cost": {"code": "class TotalLocationEventsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-3]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            spatial_unit=spatial_unit,\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalLocationEventsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'admin', 'level': 3}"], ["'day'", "'min'"], ["'out'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalNetworkObjectsSuite.time_query": {"code": "class TotalNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-1]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=make_spatial_unit(args[-2]),\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "spatial_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["{'spatial_unit_type': 'admin', 'level': 0}", "{'spatial_unit_type': 'admin', 'level': 3}"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalNetworkObjectsSuite.track_cost": {"code": "class TotalNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-1]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=make_spatial_unit(args[-2]),\n            spatial_unit=spatial_unit,\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "spatial_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["{'spatial_unit_type': 'admin', 'level': 0}", "{'spatial_unit_type': 'admin', 'level': 3}"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.UniqueSubscriberCountsSuite.time_query": {"code": "class UniqueSubscriberCountsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, hours=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.UniqueSubscriberCountsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.UniqueSubscriberCountsSuite.track_cost": {"code": "class UniqueSubscriberCountsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        spatial_unit_params = args[-2]\n        spatial_unit = make_spatial_unit(**spatial_unit_params)\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", spatial_unit=spatial_unit, hours=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.UniqueSubscriberCountsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "spatial_unit", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["True"], ["{'spatial_unit_type': 'cell'}", "{'spatial_unit_type': 'versioned-cell'}", "{'spatial_unit_type': 'admin', 'level': 3}", "{'spatial_unit_type': 'admin', 'level': 0}"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}}, "machines": {"tomte": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "ram": "131746656", "version": 1}}, "tags": {"0.0.1": 4, "0.0.2": 16, "0.0.3": 260, "0.0.4": 463, "0.0.5": 634, "0.1.0": 1015, "0.1.1": 1089, "0.1.2": 1097, "0.1.8": 9625, "0.2.0": 1153, "0.2.1": 1215, "0.2.2": 1292, "0.3.0": 1592, "0.4.0": 2486, "0.4.1": 2557, "0.4.2": 2571, "0.4.3": 2766, "0.5.0": 3261, "0.5.1": 3469, "0.5.2": 3520, "0.5.3": 3726, "0.6.0": 3957, "0.6.1": 3974, "0.6.2": 4130, "0.6.3": 4873, "0.6.4": 5305, "0.7.0": 5921, "0.8.0": 6345, "0.9.0": 7229, "0.9.1": 7386, "1.0.0": 9317, "1.1.0": 9573, "1.1.1": 9631, "1.2.0": 9831, "1.2.1": 9963, "1.3.0": 10087, "1.3.1": 10181, "1.3.2": 10243}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}