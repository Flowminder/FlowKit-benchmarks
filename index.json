{"project": "FlowKit", "project_url": "https://github.com/Flowminder/FlowKit", "show_commit_url": "https://github.com/Flowminder/FlowKit/commit/", "hash_length": 8, "revision_to_hash": {"4": "a5c731e23308928c75b5267535280aab0c7e4bf7", "16": "2ca58e1d7cdaf14c8f8f2aed545cf961acbde5c0", "260": "bf9d1ae891afe9def7406b6922931a8d16017b56", "463": "251e3977decb56c2e6a78fbee21ac57aed2b31c3", "640": "fa5a5dc823aa4292b6117aee25c7413556d2f55f", "1021": "f51abc5156fcf4815f0ff6d46ac32bf68d535fa9", "1095": "2ece3e59ffcba344f056469ebd51a005f2f95159", "1103": "1249570256e017e91eee51b23d9cdbe516a5c84c", "1159": "48b2df56923ae1cb200a7f5c97dad095c7f57ff6", "1221": "2b3b912095cc44119eb3d8597662737aa827ea9c", "1298": "91d09988496d81968032cda244e0cc1bed24f814", "1367": "d03096a0ca9b89972d02dc2e9e71c3f50963f5bf", "1370": "6776a308c9f575441333a3a2dfafc7a441568893", "1372": "d42159e39d8c9dfefa8d454455bb74c986b929dc", "1403": "7adffdf661980f4783a2ae5b4bdfb21d737cd7dd", "1420": "24f28700b3ae8afdb9c4b5490b41cbfaa337b8f4", "1489": "f5d55d88a2aa2db5539655cac243ec805f5eb446", "1598": "97013831cc176f7e7284c2e413caff901835bee1", "1599": "b73d67a8f5e84662d28a6e382af3038dbf6f0765", "1612": "b01b3d236b075d3ab9a72f925fd7f816d147388b", "2219": "f4dd8af791fab7532bbf41124c95f82d989cfb6c", "2308": "81e54ef05eb0d26fe0dd99ee74273e6722981cb2", "2318": "6d97ee7859d7845de0b8c2ec546af76ef7e53ea1", "2323": "f798f86617bd3680fd187c2fd2acaaa610b99e81", "2326": "4030a7f8fa00c481011d02e2e1ea5b5d95c1c09b", "2382": "73dbf663bab467d16d6ed9d0a2b9086ed9c9d1fc", "2458": "06f10a59680c0ab8eff05aaec916bb539b441f65", "2472": "f3da415dd1e1a184cf38f4e95a80eed75be1a5c6", "2485": "343f829e9f4383c889579ff0418f8418470e6265", "2492": "e18604361454ace228a4656d40bdaa6728fcf86f", "2543": "bc9474bd14e3f590d31e059b823e5794524456d7", "2563": "ca83f279a29adc5faf36f3831a78f6dfa3238042", "2577": "6aea272f8c7faabe89d2ae8c226c9ab1bf61ec30", "2590": "799a950e8324fc857cf0c44959f3cc4a6c964dd5", "2604": "96051c4efc13889a52539f449acfb7508d2cfaa6", "2612": "79a5cf438ce982159ef7a499ce8f55ea4d8faba0", "2625": "f413d1cf5cbc2a716640c0163ffcab9cff37b2eb", "2634": "d2aba155e3ac0a164021742d6607a491e543106d", "2662": "b8eeb053ca37017087d6938e13ac660fc7b22600", "2689": "a7bbfe97fbce28e03d6fbb5faaf6495b050ee27b", "2742": "be1c5ea7325ad4c4d0f5522cc29341c2782b8410", "2763": "626a4bcf4205ef6fdaaa6ac49d6bde7056e02575", "2769": "19919e065249bbc0fb95714824c73513a81b8e35", "2772": "fb1b85a3d1633e637c43907ddf033265733a6f6c", "2780": "49e9fb75dda8cb30a71e39211b84dc3448d2e7f5", "3267": "131c64ece8588da3bec6528405dd057d74aaaf96", "3276": "06c639c8d70b059fc0cb79d664b197868e080387", "3312": "819b340beca607406de747f8b6d99b4be941d2c0", "3344": "7c4247a7551dd7bf425ed03f9633e99d0a5494cc", "3474": "8ad6b2503358f7424b5333f148734287cec12dce", "3497": "e30a6dd95425f11648ca1fb4408964702392ebfa", "3507": "57aeec6ee6b338ba717b0357b6fe8fa1434b8b46", "3570": "9c65ef8e0f18d65eca92bec2ff8976d172b66c08", "3596": "5c283c619e8a3b2715698e95781ee8dd402c223d", "3609": "03ccb9ec747657e2644b2c370c4edf6ad52bbdf7", "3641": "a030995aa74b5744a54e605048162e36705e8716", "3656": "5adf2f1a430ee973ee4fc5085c0591642c60f114", "3714": "afee24bfc41e01ab2bc63c616b7b5e196a8421ff", "3782": "075bb7a195ffa5e6ea9fd320e7a558aeccaf0260", "3808": "52ea91e10a2f89bbda4e776fe99228d1a7632d90", "3820": "89851e2c9198e2f2d6378cd810b14cac9e969582", "3840": "85768d98b1aa146db2dc7895fa54c6c28b422d7c", "3882": "60955876d463fbb9a74c262bf122dfee34762ce9", "3910": "93151b3d55d8bdd5d278220ce5bdac769341066f", "3947": "9a653a314a0aa7ab50af6822f72c91b44c4adc10", "3974": "8a160861bb686ebbe2e284f15a1813fead158ce2", "3984": "c838f6d1ff27585a11a0766344c391487197ee66", "3987": "ba2bfd5d6215a98c334ee3cf6fda2d3d00866531", "4083": "69df744fce8fe8f75d9d4fd52c2dcb5a8d29a45a", "4092": "c85349878b1968c367f69ae19484c788efa8ea3a", "4109": "81b1b7cb61b06f06f38e6a4b6d6bb3d082571d46", "4133": "22b194a91f6aa1742fa69efa2d60e8574041fc4b", "4157": "2fcf95f2e4afec8978840698594fe7b4c2d6cddd", "4160": "93f5f1e7bf58d6e20b9a38e8ffe0c32f154e14ed", "4220": "0632cb824e4bf0c45202a659df3ae55661132676", "4259": "609822b192cbcd99802e1e180f8e39106ae7b8a4", "4289": "f92262ed3daa22998f6c73db669aaca811150805", "4325": "fc6ba1ec2e947057e06ef649028141469f4147e9", "4338": "841bb0aeb2a59a5a64ebc9fabf785f07e80de9ca", "4344": "84967d14d035f02f0c130226415655f891e4c40b", "4349": "ddc23ee97d12275c1acaddf479360d91f822b504", "4352": "22f846f49f7993d77f267395176e63328821155e", "4393": "db21526ff40b57ecb44dcd3df22f77fc5bb31f83", "4517": "2a09b5039eecbd8e061277478078cd1c40e8727c", "4628": "a24b9d922464fe924466bf157646d0d39056d79e", "4680": "00bc877c729510cdc46c14b08ba66fa313db3ce5", "4789": "53d41456761f583e98adc2cedab8a40e655adf75", "4862": "164fab7b36bc0a61b0849c631959dc3e51b44f4f", "4915": "97c01be93ed5f1dbe8c091a1ea5ac2715b8d8c9e", "5019": "ec896b300710e5eb3aa02d5eea32d0792d336354", "5059": "9b25aaacd294c9bbb3d18d889bf325bfeb957ea0", "5068": "90de5812f0c4dae5d1773f030440a5030612fc60", "5108": "bc32e37c295d0068191e4d2f2d84fee8f6f701af", "5236": "9c29a7d0dca83ce55c3d06e9ffec06765b12389c", "5260": "b01bb870c1242f6b98494dc33373f02aab380289", "5358": "a66b4eb9ee18d4186f088511cd7f1a75181a5b7a", "5420": "3089f3644197e63f627f3c9ed1b9b8cbda44c4cc", "5512": "f86f6bb62042cbf4acf4e6cf1f2c4b54d3cfe2c9", "5528": "0ebcfaadc8696719f487ea25077610c61c528b37", "5566": "76098f8d025649737cbdd5a7b308e73b81b7ceec", "5579": "c376861c146088b7003ef41fbcd32e6bba9194dc", "5589": "650ffa0f9aa363c86f4887ebd7dd4c82afb43854", "5622": "b06f039269877fde2cd6665a0b535e65372cd5d2", "5683": "fc0f5fae83a605a710f2affdaaf70d790d1bb776"}, "revision_to_date": {"4": 1541031481000, "16": 1541087949000, "260": 1541703719000, "463": 1543252162000, "640": 1544098755000, "1021": 1547543855000, "1095": 1547646794000, "1103": 1547652761000, "1159": 1547657857000, "1221": 1547724887000, "1298": 1547760280000, "1367": 1548218319000, "1370": 1548220081000, "1372": 1548220851000, "1403": 1548268741000, "1420": 1548339523000, "1489": 1548676131000, "1598": 1548928569000, "1599": 1548929830000, "1612": 1548937596000, "2219": 1551351987000, "2308": 1551736605000, "2318": 1551785643000, "2323": 1551790073000, "2326": 1551790437000, "2382": 1551846540000, "2458": 1551914548000, "2472": 1551960956000, "2485": 1552160824000, "2492": 1552303388000, "2543": 1552325793000, "2563": 1552391768000, "2577": 1552397399000, "2590": 1552413329000, "2604": 1552517051000, "2612": 1552559446000, "2625": 1552667101000, "2634": 1552762910000, "2662": 1552767049000, "2689": 1552909352000, "2742": 1553205140000, "2763": 1553276739000, "2769": 1553511299000, "2772": 1553598533000, "2780": 1553600855000, "3267": 1553814046000, "3276": 1553835135000, "3312": 1554069274000, "3344": 1554126780000, "3474": 1554233063000, "3497": 1554297581000, "3507": 1554306850000, "3570": 1554404653000, "3596": 1554475836000, "3609": 1554588618000, "3641": 1554725995000, "3656": 1554805598000, "3714": 1554892481000, "3782": 1555017982000, "3808": 1555094912000, "3820": 1555270186000, "3840": 1555331885000, "3882": 1555358968000, "3910": 1555441635000, "3947": 1555518070000, "3974": 1555604830000, "3984": 1555694370000, "3987": 1555898457000, "4083": 1556045235000, "4092": 1556100527000, "4109": 1556106380000, "4133": 1556128131000, "4157": 1556210310000, "4160": 1556265487000, "4220": 1556545764000, "4259": 1556641400000, "4289": 1556714527000, "4325": 1556830350000, "4338": 1556878853000, "4344": 1556986678000, "4349": 1557115185000, "4352": 1557218724000, "4393": 1557234716000, "4517": 1557356165000, "4628": 1557431446000, "4680": 1557497708000, "4789": 1557763392000, "4862": 1557857248000, "4915": 1557935869000, "5019": 1558031785000, "5059": 1558114469000, "5068": 1558131043000, "5108": 1558360893000, "5236": 1558558386000, "5260": 1558619987000, "5358": 1559055219000, "5420": 1559142658000, "5512": 1559601707000, "5528": 1559646147000, "5566": 1559666877000, "5579": 1559750569000, "5589": 1559810731000, "5622": 1559914301000, "5683": 1560180319000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz"], "docker": [""], "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": ["", null], "halo": [""], "machine": ["tomte"], "os": ["Linux 3.10.0-693.21.1.el7.x86_64"], "python": ["3.7"], "ram": ["131746656"], "/home/jamesharrison/synthie": ["", null], "branch": ["master"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "/home/jamesharrison/synthie": null}, {"/home/jamesharrison/synthie": "", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "halo": "", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": null}], "benchmarks": {"benchmarks.AggregateDailyLocation.time_query": {"code": "class AggregateDailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateDailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateDailyLocation.track_cost": {"code": "class AggregateDailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.query = SpatialAggregate(locations=dl)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateDailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateModalLocation.time_query": {"code": "class AggregateModalLocation:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateModalLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateModalLocation.track_cost": {"code": "class AggregateModalLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.query = SpatialAggregate(locations=ml)\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateModalLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.AggregateNetworkObjectsSuite.time_query": {"code": "class AggregateNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\", \"2016-01-07\", total_by=\"minute\", level=\"admin3\"\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.AggregateNetworkObjectsSuite.track_cost": {"code": "class AggregateNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass AggregateNetworkObjectsSuite:\n    def setup(self, *args):\n        tno = TotalNetworkObjects(\n            \"2016-01-01\", \"2016-01-07\", total_by=\"minute\", level=\"admin3\"\n        )\n        do_caching = args[-1]\n        if do_caching:\n            tno.store().result()\n        self.query = AggregateNetworkObjects(\n            total_network_objects=tno, statistic=args[-3], aggregate_by=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.AggregateNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "statistic", "aggregate_by", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["'hour'", "'month'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DFSTotalMetricAmountSuite.time_query": {"code": "class DFSTotalMetricAmountSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DFSTotalMetricAmountSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DFSTotalMetricAmountSuite.track_cost": {"code": "class DFSTotalMetricAmountSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DFSTotalMetricAmountSuite:\n    def setup(self, *args):\n        self.query = DFSTotalMetricAmount(\n            start_date=\"2016-01-01\",\n            end_date=\"2016-01-07\",\n            metric=args[-2],\n            aggregation_unit=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.DFSTotalMetricAmountSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "metric", "aggregation_unit"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'amount'", "'discount'", "'fee'", "'commission'"], ["'admin0'", "'admin3'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.DailyLocation.time_query": {"code": "class DailyLocation:\n    def time_query(self, *args):\n    \n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DailyLocation.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.DailyLocation.track_cost": {"code": "class DailyLocation:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.query = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.query.turn_off_caching()", "name": "benchmarks.DailyLocation.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.EventScoreSuite.time_query": {"code": "class EventScoreSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.EventScoreSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'versioned-cell'", "'admin3'"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.EventScoreSuite.track_cost": {"code": "class EventScoreSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass EventScoreSuite:\n    def setup(self, *args):\n        self.query = EventScore(\n            start=\"2016-01-01\", stop=\"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.EventScoreSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'versioned-cell'", "'admin3'"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.FlowSuite.time_query": {"code": "class FlowSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.FlowSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.FlowSuite.track_cost": {"code": "class FlowSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.query = Flows(*mls)\n        self.query.turn_off_caching()", "name": "benchmarks.FlowSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.HartiganClusterSuite.time_query": {"code": "class HartiganClusterSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.HartiganClusterSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.HartiganClusterSuite.track_cost": {"code": "class HartiganClusterSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass HartiganClusterSuite:\n    def setup(self, *args):\n        self.query = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", hours=args[-2], radius=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.HartiganClusterSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "hours", "radius"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["(4, 17)", "'all'"], ["0.1", "10.0"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost": {"code": "class JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass JoinedSpatialAggregateRadiusOfGyrationSuite:\n    def setup(self, *args):\n        rog = RadiusOfGyration(\"2016-01-01\", \"2016-01-02\")\n        dl = daily_location(date=\"2016-01-01\", method=\"last\")\n        if args[-2]:\n            rog.store().result()\n        if args[-1]:\n            dl.store().result()\n        self.query = JoinedSpatialAggregate(metric=rog, locations=dl, method=args[-3])\n        self.query.turn_off_caching()", "name": "benchmarks.JoinedSpatialAggregateRadiusOfGyrationSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "method", "metric_cached", "locations_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'avg'", "'max'", "'min'", "'median'", "'mode'", "'stddev'", "'variance'"], ["True", "False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.LocationIntroversionSuite.time_query": {"code": "class LocationIntroversionSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], direction=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.LocationIntroversionSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'versioned-cell'", "'admin3'", "'admin0'"], ["'in'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.LocationIntroversionSuite.track_cost": {"code": "class LocationIntroversionSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass LocationIntroversionSuite:\n    def setup(self, *args):\n        self.query = LocationIntroversion(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], direction=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.LocationIntroversionSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'versioned-cell'", "'admin3'", "'admin0'"], ["'in'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsAggregateSuite.time_query": {"code": "class MeaningfulLocationsAggregateSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsAggregateSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsAggregateSuite.track_cost": {"code": "class MeaningfulLocationsAggregateSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsAggregateSuite:\n    def setup(self, *args):\n        ml = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"unknown\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml.store().result()\n        self.query = MeaningfulLocationsAggregate(\n            meaningful_locations=ml, level=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsAggregateSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsODSuite.time_query": {"code": "class MeaningfulLocationsODSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsODSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsODSuite.track_cost": {"code": "class MeaningfulLocationsODSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsODSuite:\n    def setup(self, *args):\n        ml1 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-01\", \"2016-01-04\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-01\", stop=\"2016-01-04\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"day\",\n        )\n        ml2 = MeaningfulLocations(\n            clusters=subscriber_location_cluster(\n                \"hartigan\", \"2016-01-05\", \"2016-01-07\", radius=1.0\n            ),\n            scores=EventScore(\n                start=\"2016-01-05\", stop=\"2016-01-07\", level=\"versioned-site\"\n            ),\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=\"evening\",\n        )\n        do_caching = args[-1]\n        if do_caching:\n            ml1.store().result()\n            ml2.store().result()\n        self.query = MeaningfulLocationsOD(\n            meaningful_locations_a=ml1, meaningful_locations_b=ml2, level=args[-2]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsODSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'admin1'", "'admin3'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.MeaningfulLocationsSuite.time_query": {"code": "class MeaningfulLocationsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.MeaningfulLocationsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.MeaningfulLocationsSuite.track_cost": {"code": "class MeaningfulLocationsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass MeaningfulLocationsSuite:\n    def setup(self, *args):\n        hc = subscriber_location_cluster(\n            \"hartigan\", \"2016-01-01\", \"2016-01-07\", radius=1.0\n        )\n        es = EventScore(start=\"2016-01-01\", stop=\"2016-01-07\", level=\"versioned-site\")\n        do_caching = args[-1]\n        if do_caching:\n            hc.store().result()\n            es.store().result()\n        self.query = MeaningfulLocations(\n            clusters=hc,\n            scores=es,\n            labels={\n                \"evening\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[1e-06, -0.5], [1e-06, -1.1], [1.1, -1.1], [1.1, -0.5]]\n                    ],\n                },\n                \"day\": {\n                    \"type\": \"Polygon\",\n                    \"coordinates\": [\n                        [[-1.1, -0.5], [-1.1, 0.5], [-1e-06, 0.5], [0, -0.5]]\n                    ],\n                },\n            },\n            label=args[-2],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.MeaningfulLocationsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "label", "caching"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'day'", "'unknown'"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.ModalLocationWithCaching.time_query": {"code": "class ModalLocationWithCaching:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.ModalLocationWithCaching.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.ModalLocationWithCaching.track_cost": {"code": "class ModalLocationWithCaching:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.query = ModalLocation(*daily_locs)\n        self.query.turn_off_caching()", "name": "benchmarks.ModalLocationWithCaching.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.RadiusOfGyrationSuite.time_query": {"code": "class RadiusOfGyrationSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.RadiusOfGyrationSuite.time_query", "number": 0, "param_names": [], "params": [], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.RadiusOfGyrationSuite.track_cost": {"code": "class RadiusOfGyrationSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass RadiusOfGyrationSuite:\n    def setup(self, *args):\n        self.query = RadiusOfGyration(\"2016-01-01\", \"2016-01-07\")\n        self.query.turn_off_caching()", "name": "benchmarks.RadiusOfGyrationSuite.track_cost", "param_names": [], "params": [], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalLocationEventsSuite.time_query": {"code": "class TotalLocationEventsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalLocationEventsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalLocationEventsSuite.track_cost": {"code": "class TotalLocationEventsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.query = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalLocationEventsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.TotalNetworkObjectsSuite.time_query": {"code": "class TotalNetworkObjectsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=args[-2],\n            level=args[-1],\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalNetworkObjectsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "level"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["'admin0'", "'admin3'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.TotalNetworkObjectsSuite.track_cost": {"code": "class TotalNetworkObjectsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass TotalNetworkObjectsSuite:\n    def setup(self, *args):\n        self.query = TotalNetworkObjects(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            total_by=args[-3],\n            network_object=args[-2],\n            level=args[-1],\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.TotalNetworkObjectsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "total_by", "network_object", "level"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'minute'", "'day'"], ["'cell'", "'versioned-cell'", "'versioned-site'"], ["'admin0'", "'admin3'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}, "benchmarks.UniqueSubscriberCountsSuite.time_query": {"code": "class UniqueSubscriberCountsSuite:\n    def time_query(self, *args):\n        _ = self.query.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.UniqueSubscriberCountsSuite.time_query", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'versioned-cell'", "'admin3'", "'admin0'"], ["(4, 17)", "'all'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "0", "warmup_time": -1}, "benchmarks.UniqueSubscriberCountsSuite.track_cost": {"code": "class UniqueSubscriberCountsSuite:\n    def track_cost(self, *args):\n        return self.query.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        flowdb_port=flowdb_container.port,\n        flowdb_host=flowdb_container.host,\n        flowdb_password=\"foo\",\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(f\"Connected. Resetting cache.\")\n    flowmachine.core.cache.reset_cache(\n        flowmachine.core.Query.connection, flowmachine.core.Query.redis\n    )\n    if reuse_containers() and keep_containers_alive():\n        pass\n    elif reuse_containers():\n        update_containers_to_remove_file(flowdb_container, redis_container)\n        if not keep_flowdb_volumes():\n            update_volumes_to_remove_file(flowdb_config)\n\nclass UniqueSubscriberCountsSuite:\n    def setup(self, *args):\n        self.query = UniqueSubscriberCounts(\n            \"2016-01-01\", \"2016-01-07\", level=args[-2], hours=args[-1]\n        )\n        self.query.turn_off_caching()", "name": "benchmarks.UniqueSubscriberCountsSuite.track_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "hours"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'versioned-cell'", "'admin3'", "'admin0'"], ["(4, 17)", "'all'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0"}}, "machines": {"tomte": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "machine": "tomte", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "ram": "131746656", "version": 1}}, "tags": {"0.0.1": 4, "0.0.2": 16, "0.0.3": 260, "0.0.4": 463, "0.0.5": 640, "0.1.0": 1021, "0.1.1": 1095, "0.1.2": 1103, "0.2.0": 1159, "0.2.1": 1221, "0.2.2": 1298, "0.3.0": 1598, "0.4.0": 2492, "0.4.1": 2563, "0.4.2": 2577, "0.4.3": 2772, "0.5.0": 3267, "0.5.1": 3497, "0.5.2": 3570, "0.5.3": 3840, "0.6.0": 4092, "0.6.1": 4109, "0.6.2": 4289, "0.6.3": 5059, "0.6.4": 5528}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}