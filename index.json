{"project": "FlowKit", "project_url": "https://github.com/Flowminder/FlowKit", "show_commit_url": "https://github.com/Flowminder/FlowKit/commit/", "hash_length": 8, "revision_to_hash": {"4": "a5c731e23308928c75b5267535280aab0c7e4bf7", "16": "2ca58e1d7cdaf14c8f8f2aed545cf961acbde5c0", "260": "bf9d1ae891afe9def7406b6922931a8d16017b56", "463": "251e3977decb56c2e6a78fbee21ac57aed2b31c3", "640": "fa5a5dc823aa4292b6117aee25c7413556d2f55f", "1064": "f51abc5156fcf4815f0ff6d46ac32bf68d535fa9", "1138": "2ece3e59ffcba344f056469ebd51a005f2f95159", "1146": "1249570256e017e91eee51b23d9cdbe516a5c84c", "1202": "48b2df56923ae1cb200a7f5c97dad095c7f57ff6", "1264": "2b3b912095cc44119eb3d8597662737aa827ea9c", "1341": "91d09988496d81968032cda244e0cc1bed24f814", "1465": "d03096a0ca9b89972d02dc2e9e71c3f50963f5bf", "1468": "6776a308c9f575441333a3a2dfafc7a441568893", "1470": "d42159e39d8c9dfefa8d454455bb74c986b929dc", "1509": "7adffdf661980f4783a2ae5b4bdfb21d737cd7dd", "1527": "24f28700b3ae8afdb9c4b5490b41cbfaa337b8f4", "1597": "f5d55d88a2aa2db5539655cac243ec805f5eb446"}, "revision_to_date": {"4": 1541031481000, "16": 1541087949000, "260": 1541703719000, "463": 1543252162000, "640": 1544098755000, "1064": 1547543855000, "1138": 1547646794000, "1146": 1547652761000, "1202": 1547657857000, "1264": 1547724887000, "1341": 1547760280000, "1465": 1548218319000, "1468": 1548220081000, "1470": 1548220851000, "1509": 1548268741000, "1527": 1548339523000, "1597": 1548676131000}, "params": {"arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz"], "docker": [""], "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": [""], "halo": [""], "machine": ["tomte.geodata.org.uk"], "os": ["Linux 3.10.0-693.21.1.el7.x86_64"], "python": ["3.7"], "ram": ["131746656"], "branch": ["master"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "docker": "", "git+ssh://git@github.com/Flowminder/synthie.git#egg=synthie": "", "halo": "", "machine": "tomte.geodata.org.uk", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "python": "3.7", "ram": "131746656", "branch": "master"}], "benchmarks": {"benchmarks.AggregateDailyLocation.time_aggregate_daily_location": {"code": "class AggregateDailyLocation:\n    def time_aggregate_daily_location(self, *args):\n    \n        _ = self.dl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.dl = dl.aggregate()\n        self.dl.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateDailyLocation.time_aggregate_daily_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "2b5a292afc5db7a8707dcce8c29f1107aec1901d4cc92e4dac82f089db4cfd69", "warmup_time": -1}, "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost": {"code": "class AggregateDailyLocation:\n    def track_aggregate_daily_location_cost(self, *args):\n        return self.dl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateDailyLocation:\n    def setup(self, *args):\n        dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        if args[-2]:\n            dl.store().result()\n        self.dl = dl.aggregate()\n        self.dl.turn_off_caching()", "name": "benchmarks.AggregateDailyLocation.track_aggregate_daily_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "bde1065ea280e8397b25cbb92d172580bc35e02afaa92451459414cc7ca68e3f"}, "benchmarks.AggregateModalLocation.time_aggregate_modal_location": {"code": "class AggregateModalLocation:\n    def time_aggregate_modal_location(self, *args):\n        _ = self.ml.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.ml = ml.aggregate()\n        self.ml.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.AggregateModalLocation.time_aggregate_modal_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "91702f6f9feee787e59bea38e7c6db1214b1b9ed48062c08ce05d02f309f61be", "warmup_time": -1}, "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost": {"code": "class AggregateModalLocation:\n    def track_aggregate_modal_location_cost(self, *args):\n        return self.ml.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass AggregateModalLocation:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        ml = ModalLocation(*daily_locs)\n        if args[-1]:\n            ml.store().result()\n        self.ml = ml.aggregate()\n        self.ml.turn_off_caching()", "name": "benchmarks.AggregateModalLocation.track_aggregate_modal_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "is_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["True", "False"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "8552ae0b97b70fe5e5b73091119563c77561a81d32bb55ce96aacf388fb97671"}, "benchmarks.DailyLocation.time_daily_location": {"code": "class DailyLocation:\n    def time_daily_location(self, *args):\n    \n        _ = self.dl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.dl.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.DailyLocation.time_daily_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "f344a70e9089de3e7d94dd36a777132803a7aee682b002ae14605f0375c7dad1", "warmup_time": -1}, "benchmarks.DailyLocation.track_daily_location_cost": {"code": "class DailyLocation:\n    def track_daily_location_cost(self, *args):\n        return self.dl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass DailyLocation:\n    def setup(self, *args):\n        self.dl = daily_location(date=\"2016-01-01\", method=args[-1])\n        self.dl.turn_off_caching()", "name": "benchmarks.DailyLocation.track_daily_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "1807c2e59a83bc612ca5c75db5036cb51417bff32882f36b30cff37b3af722ea"}, "benchmarks.FlowSuite.time_flow": {"code": "class FlowSuite:\n    def time_flow(self, *args):\n        _ = self.fl.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.fl = Flows(*mls)\n        self.fl.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.FlowSuite.time_flow", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "b9cd4d8dbff08109271998cabe7a7470758112e8f9f912efc94f06e00112ada7", "warmup_time": -1}, "benchmarks.FlowSuite.track_flow_cost": {"code": "class FlowSuite:\n    def track_flow_cost(self, *args):\n        return self.fl.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass FlowSuite:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        daily_locs = [daily_location(date=date) for date in dates]\n        mls = [ModalLocation(*daily_locs[:3]), ModalLocation(*daily_locs[3:])]\n        stored_mls = [ml.store() for ml in mls[: args[-1]]]\n        for ml in stored_mls:\n            ml.result()\n        self.fl = Flows(*mls)\n        self.fl.turn_off_caching()", "name": "benchmarks.FlowSuite.track_flow_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "1", "2"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "0f8aaf415e19b6a68444ce7a0066725d61fe4fce9c3ef140100dc61eceba8421"}, "benchmarks.ModalLocationWithCaching.time_modal_location": {"code": "class ModalLocationWithCaching:\n    def time_modal_location(self, *args):\n        _ = self.ml.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.ml = ModalLocation(*daily_locs)\n        self.ml.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.ModalLocationWithCaching.time_modal_location", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "567c00654fab574eaf7ae4c9b6bc3e6e11f60cb9ffb6e5144eebf09b2c650a35", "warmup_time": -1}, "benchmarks.ModalLocationWithCaching.track_modal_location_cost": {"code": "class ModalLocationWithCaching:\n    def track_modal_location_cost(self, *args):\n        return self.ml.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass ModalLocationWithCaching:\n    def setup(self, *args):\n        dates = [\n            \"2016-01-01\",\n            \"2016-01-02\",\n            \"2016-01-03\",\n            \"2016-01-04\",\n            \"2016-01-05\",\n            \"2016-01-06\",\n            \"2016-01-07\",\n        ]\n        stored_daily_locs = [\n            daily_location(date=date, method=args[-1]).store()\n            for date in dates[: args[-2]]\n        ]\n        for d in stored_daily_locs:\n            d.result()\n        daily_locs = [daily_location(date=date, method=args[-1]) for date in dates]\n        self.ml = ModalLocation(*daily_locs)\n        self.ml.turn_off_caching()", "name": "benchmarks.ModalLocationWithCaching.track_modal_location_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "n_cached", "daily_location_method"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["0", "3", "7"], ["'last'", "'most-common'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "ffdd02ede688977fad2c1ac935a3a459b1ec767b2fd845b3b12add9b4d948f7a"}, "benchmarks.TotalLocationEventsSuite.time_total_location_events": {"code": "class TotalLocationEventsSuite:\n    def time_total_location_events(self, *args):\n        _ = self.tle.store().result()\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.tle = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.tle.turn_off_caching()", "min_run_count": 2, "name": "benchmarks.TotalLocationEventsSuite.time_total_location_events", "number": 0, "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "processes": 2, "repeat": 0, "sample_time": 0.01, "timeout": 1200, "type": "time", "unit": "seconds", "version": "c8c82ae515935064c23d58c8d65ecd86af326292491da85307e99fe282d0ef6b", "warmup_time": -1}, "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost": {"code": "class TotalLocationEventsSuite:\n    def track_total_location_events_cost(self, *args):\n        return self.tle.explain(format=\"json\")[0][\"Plan\"][\"Total Cost\"]\n\ndef setup(*args):\n    print(f\"Running setup for {args}\")\n    docker_client = docker.from_env()\n\n    flowdb_config = FlowDBConfig(*args[:6], root_directory=get_benchmark_dbs_dir())\n    flowdb_container = flowdb_config.create_db(docker_client)\n    redis_container = get_redis(docker_client)\n    flowmachine.connect(\n        db_port=flowdb_container.port,\n        db_host=flowdb_container.host,\n        redis_port=redis_container.port,\n        redis_host=redis_container.host,\n        redis_password=\"fm_redis\",\n    )\n    flowmachine.redis_container = redis_container\n    flowmachine.flowdb_container = flowdb_container\n    flowmachine.flowdb_config = flowdb_config\n    print(\n        f\"Connected. Flushing redis '{redis_container.name}' on {redis_container.host}:{redis_container.port}.\"\n    )\n    flowmachine.core.Query.redis.flushdb()\n    print(\"Wiping any cache tables.\")\n    for q in flowmachine.core.Query.get_stored():\n        q.invalidate_db_cache()\n\nclass TotalLocationEventsSuite:\n    def setup(self, *args):\n        self.tle = TotalLocationEvents(\n            \"2016-01-01\",\n            \"2016-01-07\",\n            level=args[-3],\n            interval=args[-2],\n            direction=args[-1],\n        )\n        self.tle.turn_off_caching()", "name": "benchmarks.TotalLocationEventsSuite.track_total_location_events_cost", "param_names": ["num_days", "num_subscribers", "num_cells", "num_calls_per_day", "analyze", "cluster", "jit", "level", "interval", "direction"], "params": [["7"], ["1000"], ["400"], ["10000"], ["True"], ["True"], ["False"], ["'cell'", "'admin3'"], ["'day'", "'min'"], ["'out'", "'both'"]], "timeout": 1200, "type": "track", "unit": "unit", "version": "47813d71b2590d9dd53ba7111486f1e6d9b883cd9c6137940a81ed2eaef89b58"}}, "machines": {"tomte.geodata.org.uk": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz", "machine": "tomte.geodata.org.uk", "os": "Linux 3.10.0-693.21.1.el7.x86_64", "ram": "131746656", "version": 1}}, "tags": {"0.0.1": 4, "0.0.2": 16, "0.0.3": 260, "0.0.4": 463, "0.0.5": 640, "0.1.0": 1064, "0.1.1": 1138, "0.1.2": 1146, "0.2.0": 1202, "0.2.1": 1264, "0.2.2": 1341}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}